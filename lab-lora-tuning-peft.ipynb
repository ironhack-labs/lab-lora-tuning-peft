{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9Y40X0WCY_H"
   },
   "source": [
    "# Lab | Introduction to LoRA Tuning using PEFT from Hugging Face\n",
    "<!-- ### Fine-tune a Foundational Model effortlessly -->\n",
    "\n",
    "**Note:** This is more or less the same notebook you saw in the previous lesson, but that is ok. This is an LLM fine-tuning lab. In class we used a set of datasets and models, and in the labs you are required to change the LLMs models and the datasets including the pre-processing pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCinY2l-upqy"
   },
   "source": [
    "# LoRA Tuning\n",
    "\n",
    "In this notebook you are being introduced to how to apply LoRA Tuning with the PEFT library to a pre-trained model.\n",
    "\n",
    "For a complete list of Models compatible with PEFT refer to their [documentation](https://huggingface.co/docs/peft/main/en/index#supported-methods).\n",
    "\n",
    "A short sample of models families available to be trained with PEFT are: Bloom, Llama, GPT-J, GPT-2, BERT... and more. Hugging Face is working hard to bring more Models to the Library.\n",
    "\n",
    "## Brief introduction to LoRA Tuning.\n",
    "LoRA is a re-parameterization technique. Its operation is simple, complex, and brilliant at the same time. It involves reducing the size of the matrices to be trained by dividing them in such a way that when multiplied, they yield the original matrix.\n",
    "\n",
    "The weights that are modified are those of the reduced matrices, not the original matrix. It's better visualized in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cp_7rR4Nx7My"
   },
   "source": [
    "![Matrices_LoRA.webp](data:image/webp;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oSLJkXty-t_"
   },
   "source": [
    "We have an original matrix of 50x50, which means we would have to modify about 2500 parameters. However, as we know, if we multiply two matrices of (2x50) and (50x2), we obtain a 50x50 matrix. Yet, these two matrices are formed by only 100 parameters each. In other words, for the reduced matrices, we need to modify a total of 200 parameters compared to the 2500 of the original matrix. This represents a 92% reduction, and the larger the original matrix, the greater the percentage of savings.\n",
    "\n",
    "In Language Models like GPT-3 or any of the current ones with LoRA, it's possible that we only need to train about 0.02% of the original parameters. This varies for each model. The best part is that the obtained result is very similar to that of full fine-tuning, in some cases, it can even be better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "620MdVMk7iUS"
   },
   "source": [
    "# Load the PEFT and Datasets Libraries.\n",
    "\n",
    "The PEFT library contains the Hugging Face implementation of differente fine-tuning techniques, like LoRA Tuning.\n",
    "\n",
    "Using the Datasets library we have acces to a huge amount of Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_UyyuMGnCPjA",
    "outputId": "20ea95ed-d64b-42e2-eb82-01aabd5f030c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install -q peft==0.8.2\n",
    "#!pip install -q datasets==2.16.1\n",
    "#!pip install ipywidgets==7.7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3axo9np4tRnr",
    "outputId": "5a995037-bfe1-416f-d401-cc2942820a7d"
   },
   "outputs": [],
   "source": [
    "#pip uninstall -y gcsfs fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JyABTlBVtXlH",
    "outputId": "427748a3-fe80-4811-f215-ecd2778f148f"
   },
   "outputs": [],
   "source": [
    "#pip install datasets==2.16.1 fsspec[http]==2023.10.0 gcsfs==2023.10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOnJlBY-81Wl"
   },
   "source": [
    "From the transformers library we import the necesary classes to import the model and the tokenizer.\n",
    "\n",
    "Then we can load the Tokenizer and the model.\n",
    "\n",
    "Bloom is one of the smallest and smarter model available to be trained with PEFT Library using Prompt Tuning. You can use either of the models in the Bloom Family, I encorage you to use at least two of them and see the differences.\n",
    "\n",
    "I'm using the smallest one just to spend less time trainig, and avoid memory problems in Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vziwd2UuCYGl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"bigscience/bloom-560m\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "foundation_model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qtc1gbK39Hp7"
   },
   "source": [
    "## Inference with the pre-trained model.\n",
    "I'm going to do a test with the pre-trained model without fine-tuning, to see if something changes after the fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jak6FzpvFTHk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this function returns the outputs from the model received, and inputs.\n",
    "def get_outputs(model, inputs, max_new_tokens=100): #play with this function inputs and see if you get something interesting\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        repetition_penalty=1.5, #Avoid repetition.\n",
    "        num_beams=1,  # Enable beam search for better quality\n",
    "        do_sample=True,  # Enable sampling\n",
    "        temperature=0.7,  # Control randomness\n",
    "        early_stopping=True, #The model can stop before reach the max_length\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkFqjS459jAa"
   },
   "source": [
    "The dataset used for the fine-tuning contains prompts to be used with Large Language Models.\n",
    "\n",
    "I'm going to request the pre-trained model that acts like a motivational coach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3BAYg7czFYeK",
    "outputId": "8f1242dc-099c-4a5b-d586-898648c6696c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I want you to act as a motivational coach. You need someone who is willing and able, not afraid or discouraged.\\nYou may ask me why I am doing this? Your brain needs your work out so that it can feel good about its ability while also giving yourself some extra time over the course']\n"
     ]
    }
   ],
   "source": [
    "#Inference original model\n",
    "input_sentences = tokenizer(\"I want you to act as a motivational coach.\", return_tensors=\"pt\")\n",
    "foundational_outputs_sentence = get_outputs(foundation_model, input_sentences, max_new_tokens=50)\n",
    "\n",
    "print(tokenizer.batch_decode(foundational_outputs_sentence, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcD9GPXYxz-D"
   },
   "source": [
    "# *Results obtained from the first run of Inference Original Model:*\n",
    "\n",
    "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:676: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
    "  warnings.warn(\n",
    "['I want you to act as a motivational coach. You will be able to:\\n• Develop and implement strategies for improving your performance, including: • Motivating yourself;']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TdyCM4m6j3je"
   },
   "source": [
    "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
    "  warnings.warn(\n",
    "['I want you to act as a motivational coach. You will be able to:\\n• Develop and implement strategies for improving your performance, including: • Motivating yourself;']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MwwaoiHNzBEe",
    "outputId": "9efe807c-3f3d-4104-90d1-a02febc62b89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I want you to act as a motivational coach. I want you to be a leader. I want you to be a mentor. I want you to be a teacher. I want you to be a doctor. I want you to be a lawyer. I want you to be a politician. I want you to be a scientist. I want you to be a mathematician. I want you to be a physicist. I want you to be a mathematician. I want you to be a physicist. I want you to be a mathematician']\n"
     ]
    }
   ],
   "source": [
    "# Below is a recomended code to improve quality of the original model without tunning\n",
    "'''\n",
    "# Tokenize the input prompt\n",
    "input_sentences = tokenizer(\"I want you to act as a motivational coach.\", return_tensors=\"pt\")\n",
    "\n",
    "# Generate outputs with refined generation parameters\n",
    "foundational_outputs_sentence = foundation_model.generate(\n",
    "    input_ids=input_sentences[\"input_ids\"],\n",
    "    attention_mask=input_sentences[\"attention_mask\"],\n",
    "    max_new_tokens=100,  # Limit the maximum number of new tokens\n",
    "    repetition_penalty=1.5,  # Penalize repeated words or phrases\n",
    "    early_stopping=True,  # Stop if an <eos> token is found\n",
    "    num_beams=5  # Enable beam search for better quality generation\n",
    ")\n",
    "\n",
    "# Decode the generated tokens into text and skip special tokens\n",
    "decoded_output = tokenizer.batch_decode(foundational_outputs_sentence, skip_special_tokens=True)\n",
    "\n",
    "# Print the generated text\n",
    "print(decoded_output)'''\n",
    "\n",
    "'''Code tested refer to below output printed:\n",
    "\n",
    "['I want you to act as a motivational coach. I want you to be a leader.\n",
    "I want you to be a mentor. I want you to be a teacher. I want you to be a doctor.\n",
    " I want you to be a lawyer. I want you to be a politician. I want you to be a scientist.\n",
    " I want you to be a mathematician. I want you to be a physicist.\n",
    " I want you to be a mathematician. I want you to be a physicist.\n",
    " I want you to be a mathematician']'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQUGY47p9ysI"
   },
   "source": [
    "Not sure if the answer is correct or not, but for sure is not a prompt. We need to train our model if we want that acts like a prompt engineer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FL5L_DcR9ggA"
   },
   "source": [
    "# Preparing the Dataset.\n",
    "The Dataset used is:\n",
    "\n",
    "https://huggingface.co/datasets/fka/awesome-chatgpt-prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "DyIMQ7IHFbIx",
    "outputId": "85f5f877-11b0-4556-8b04-20e61194d8b7",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = \"fka/awesome-chatgpt-prompts\"\n",
    "\n",
    "#Create the Dataset to create prompts.\n",
    "data = load_dataset(dataset)\n",
    "data = data.map(lambda samples: tokenizer(samples[\"prompt\"]), batched=True)\n",
    "train_sample = data[\"train\"].select(range(50))\n",
    "\n",
    "train_sample = train_sample.remove_columns('act')\n",
    "\n",
    "display(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gmlZY3fk_9fm",
    "outputId": "ee307b03-7798-4719-c95d-e235fca0a5ec",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': ['Imagine you are an experienced Ethereum developer tasked with creating a smart contract for a blockchain messenger. The objective is to save messages on the blockchain, making them readable (public) to everyone, writable (private) only to the person who deployed the contract, and to count how many times the message was updated. Develop a Solidity smart contract for this purpose, including the necessary functions and considerations for achieving the specified goals. Please provide the code and any relevant explanations to ensure a clear understanding of the implementation.'], 'input_ids': [[186402, 1152, 1306, 660, 72560, 28857, 167625, 84544, 20165, 376, 1002, 26168, 267, 30479, 17477, 613, 267, 120755, 238776, 17, 1387, 47881, 632, 427, 14565, 29866, 664, 368, 120755, 15, 16997, 4054, 136044, 375, 4859, 12, 427, 39839, 15, 9697, 1242, 375, 13614, 12, 3804, 427, 368, 2298, 5268, 109891, 368, 17477, 15, 530, 427, 11210, 4143, 7112, 11866, 368, 11011, 1620, 36320, 17, 21265, 267, 11550, 90533, 30479, 17477, 613, 1119, 27343, 15, 11762, 368, 18348, 16231, 530, 127246, 613, 94510, 368, 25605, 55790, 17, 29901, 13842, 368, 4400, 530, 2914, 24466, 184637, 427, 22646, 267, 11285, 32391, 461, 368, 17786, 17]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "print(train_sample[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qP-HrDq8laJM",
    "outputId": "0ebb2e59-0bb6-4915-9e37-9bff4c0cf7a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': ['Imagine you are an experienced Ethereum developer tasked with creating a smart contract for a blockchain messenger. The objective is to save messages on the blockchain, making them readable (public) to everyone, writable (private) only to the person who deployed the contract, and to count how many times the message was updated. Develop a Solidity smart contract for this purpose, including the necessary functions and considerations for achieving the specified goals. Please provide the code and any relevant explanations to ensure a clear understanding of the implementation.', \"Using WebPilot, create an outline for an article that will be 2,000 words on the keyword 'Best SEO prompts' based on the top 10 results from Google. Include every relevant heading possible. Keep the keyword density of the headings high. For each section of the outline, include the word count. Include FAQs section in the outline too, based on people also ask section from Google for the keyword. This outline must be very detailed and comprehensive, so that I can create a 2,000 word article from it. Generate a long list of LSI and NLP keywords related to my keyword. Also include any other words related to the keyword. Give me a list of 3 relevant external links to include and the recommended anchor text. Make sure they’re not competing articles. Split the outline into part 1 and part 2.\", 'I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd', 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"', 'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conversation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"'], 'input_ids': [[186402, 1152, 1306, 660, 72560, 28857, 167625, 84544, 20165, 376, 1002, 26168, 267, 30479, 17477, 613, 267, 120755, 238776, 17, 1387, 47881, 632, 427, 14565, 29866, 664, 368, 120755, 15, 16997, 4054, 136044, 375, 4859, 12, 427, 39839, 15, 9697, 1242, 375, 13614, 12, 3804, 427, 368, 2298, 5268, 109891, 368, 17477, 15, 530, 427, 11210, 4143, 7112, 11866, 368, 11011, 1620, 36320, 17, 21265, 267, 11550, 90533, 30479, 17477, 613, 1119, 27343, 15, 11762, 368, 18348, 16231, 530, 127246, 613, 94510, 368, 25605, 55790, 17, 29901, 13842, 368, 4400, 530, 2914, 24466, 184637, 427, 22646, 267, 11285, 32391, 461, 368, 17786, 17], [39312, 15202, 51, 46712, 15, 7932, 660, 67606, 613, 660, 8723, 861, 2152, 722, 415, 15, 1874, 17848, 664, 368, 70062, 38038, 388, 174249, 39841, 9427, 11173, 664, 368, 7921, 1581, 9649, 1485, 8943, 17, 137151, 6216, 24466, 87480, 6399, 17, 109988, 368, 70062, 32993, 461, 368, 10082, 3164, 6426, 17, 5070, 5546, 13773, 461, 368, 67606, 15, 13756, 368, 14679, 11210, 17, 137151, 209147, 86, 13773, 361, 368, 67606, 10136, 15, 11173, 664, 6199, 3466, 9283, 13773, 1485, 8943, 613, 368, 70062, 17, 3904, 67606, 6591, 722, 5636, 53180, 530, 65604, 15, 1427, 861, 473, 1400, 7932, 267, 415, 15, 1874, 14679, 8723, 1485, 718, 17, 143293, 267, 3829, 4737, 461, 499, 49863, 530, 557, 103096, 135158, 17251, 427, 2670, 70062, 17, 30497, 13756, 2914, 3390, 17848, 17251, 427, 368, 70062, 17, 121045, 1074, 267, 4737, 461, 735, 24466, 26331, 31437, 427, 13756, 530, 368, 49635, 91770, 5484, 17, 42187, 11097, 3291, 87099, 1130, 174169, 14476, 17, 152830, 368, 67606, 3727, 1571, 404, 530, 1571, 415, 17], [44, 4026, 1152, 427, 1769, 661, 267, 104105, 28434, 17, 473, 2152, 4105, 49123, 530, 1152, 2152, 57502, 1002, 3595, 368, 28434, 3403, 6460, 17, 473, 4026, 1152, 427, 3804, 57502, 1002, 368, 28434, 10014, 14652, 2592, 19826, 4400, 10973, 15, 530, 16915, 4384, 17, 727, 1130, 11602, 184637, 17, 727, 1130, 4105, 49123, 35262, 473, 32247, 1152, 427, 727, 1427, 17, 3262, 707, 3423, 427, 13485, 1152, 7747, 361, 170205, 15, 707, 2152, 727, 1427, 1331, 55385, 5484, 14652, 6291, 999, 117805, 731, 29726, 1119, 96, 17, 2670, 3968, 9361, 632, 269, 42512], [44, 4026, 1152, 427, 1769, 661, 660, 7165, 242510, 15, 102509, 9428, 280, 530, 11754, 762, 17, 473, 2152, 32741, 427, 1152, 361, 2914, 16340, 530, 1152, 2152, 17859, 368, 16340, 15, 53918, 718, 530, 12300, 361, 368, 130555, 530, 44649, 6997, 461, 2670, 5484, 15, 361, 7165, 17, 473, 4026, 1152, 427, 29495, 2670, 87695, 142328, 46315, 17848, 530, 93150, 1002, 3172, 40704, 530, 104189, 15, 29923, 6626, 7165, 17848, 530, 93150, 17, 109988, 368, 30916, 5025, 15, 1965, 5219, 4054, 3172, 140624, 17, 473, 4026, 1152, 427, 3804, 57502, 368, 62948, 15, 368, 95622, 530, 16915, 4384, 15, 727, 1130, 11602, 184637, 17, 9293, 3968, 42932, 632, 567, 10928, 69, 7798, 84227, 458, 4112, 92, 333, 5967, 699, 5486, 57616, 84227, 35881, 184849], [44, 4026, 1152, 427, 1769, 661, 660, 33322, 259, 17, 473, 2152, 722, 368, 42581, 530, 1152, 2152, 9283, 1074, 368, 33322, 11732, 613, 368, 9747, 9832, 67, 8748, 17, 473, 4026, 1152, 427, 3804, 57502, 661, 368, 33322, 259, 17, 9227, 1130, 11602, 1728, 368, 56462, 919, 14275, 17, 473, 4026, 1152, 427, 3804, 727, 368, 33322, 1002, 1074, 17, 115072, 1074, 368, 11732, 530, 18688, 613, 2670, 41259, 17, 9227, 1130, 11602, 184637, 17, 115072, 1074, 368, 11732, 2592, 1331, 2592, 3269, 660, 33322, 259, 4636, 530, 18688, 613, 2670, 41259, 17, 9293, 3968, 42932, 632, 17959, 44824]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "print(train_sample[:5]) # Display the first 5 samples for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g4201SXs3hND",
    "outputId": "d3991835-f649-44a6-a615-a6fbcf23f554"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              prompt  \\\n",
      "0  Imagine you are an experienced Ethereum develo...   \n",
      "1  Using WebPilot, create an outline for an artic...   \n",
      "2  I want you to act as a linux terminal. I will ...   \n",
      "3  I want you to act as an English translator, sp...   \n",
      "4  I want you to act as an interviewer. I will be...   \n",
      "\n",
      "                                           input_ids  \\\n",
      "0  [186402, 1152, 1306, 660, 72560, 28857, 167625...   \n",
      "1  [39312, 15202, 51, 46712, 15, 7932, 660, 67606...   \n",
      "2  [44, 4026, 1152, 427, 1769, 661, 267, 104105, ...   \n",
      "3  [44, 4026, 1152, 427, 1769, 661, 660, 7165, 24...   \n",
      "4  [44, 4026, 1152, 427, 1769, 661, 660, 33322, 2...   \n",
      "\n",
      "                                      attention_mask  \n",
      "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n"
     ]
    }
   ],
   "source": [
    "# Convert the dataset to a pandas DataFrame for easier visualization\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(train_sample)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "stmQwYtsmEsx",
    "outputId": "63012ce2-47d1-4725-c950-f95c25a71fcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum token length: 168\n"
     ]
    }
   ],
   "source": [
    "max_length = max(len(ids) for ids in train_sample[\"input_ids\"])\n",
    "print(f\"Maximum token length: {max_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NW4ioZ_x3_aj",
    "outputId": "47a1119f-18ae-4ae1-f26c-4244f7667a58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     50.000000\n",
      "mean      94.440000\n",
      "std       16.503753\n",
      "min       72.000000\n",
      "25%       85.000000\n",
      "50%       89.000000\n",
      "75%      103.750000\n",
      "max      168.000000\n",
      "Name: token_length, dtype: float64\n",
      "Empty DataFrame\n",
      "Columns: [prompt, input_ids, attention_mask, token_length]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "##Check token length:\n",
    "##Check how many tokens the longest prompts have,\n",
    "#to decide if you need to truncate or split them.\n",
    "\n",
    "# Calculate the length of each prompt in tokens\n",
    "df['token_length'] = df['input_ids'].apply(len)\n",
    "\n",
    "# Check the longest prompts\n",
    "print(df['token_length'].describe())\n",
    "print(df[df['token_length'] > 512])  # Example for models with 512-token limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1E02cjaT48tB"
   },
   "source": [
    "# **Token Length Validation Results**\n",
    "Summary Statistics:\n",
    "\n",
    "1. Tokens per Prompt:\n",
    "\n",
    "- Mean: 94.44 tokens.\n",
    "\n",
    "- Max: 168 tokens.\n",
    "\n",
    "- Min: 72 tokens.\n",
    "\n",
    "- The token lengths are fairly consistent, with a standard deviation of ~16.5.\n",
    "\n",
    "2. Long Prompts (more than 512 tokens):\n",
    "\n",
    "- No examples exceed the 512 token limit.\n",
    "\n",
    "- The check df[df['token_length'] > 512] returned an empty DataFrame, confirming that all samples fit within the model’s limits.\n",
    "\n",
    "This ensures that the dataset is within the typical limits for most language models, avoiding the need for truncation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JnpndgA5ot1"
   },
   "source": [
    "Interpretation:\n",
    "\n",
    "Prepared dataset: There are no excessively long prompts, so there is no need to truncate or split inputs.\n",
    "\n",
    "Efficiency: With relatively short prompts (maximum 160 tokens), the model should process them efficiently during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVPAJsrUAHiJ"
   },
   "source": [
    "# Fine-Tuning.\n",
    "First is necesary create a LoRA config.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uCalslQFGL7K"
   },
   "outputs": [],
   "source": [
    "# TARGET_MODULES\n",
    "# https://github.com/huggingface/peft/blob/39ef2546d5d9b8f5f8a7016ec10657887a867041/src/peft/utils/other.py#L220\n",
    "\n",
    "import peft\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "\n",
    "lora_config = LoraConfig(#play with these config inputs\n",
    "    r=4, #As bigger the R bigger the parameters to train.\n",
    "    lora_alpha=1, # a scaling factor that adjusts the magnitude of the weight matrix. Usually set to 1\n",
    "    target_modules=[\"query_key_value\"], #You can obtain a list of target modules in the URL above.\n",
    "    lora_dropout=0.05, #Helps to avoid Overfitting.\n",
    "    bias=\"lora_only\", # this specifies if the bias parameter should be trained.\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUddynl0B1Ck"
   },
   "source": [
    "The most important parameter is **r**, it defines how many parameters will be trained. As bigger the valuer more parameters are trained, but it means that the model will be able to learn more complicated relations between input and output.\n",
    "\n",
    "Yo can find a list of the **target_modules** available on the [Hugging Face Documentation]( https://github.com/huggingface/peft/blob/39ef2546d5d9b8f5f8a7016ec10657887a867041/src/peft/utils/other.py#L220)\n",
    "\n",
    "**lora_dropout** is like the commom dropout is used to avoid overfitting.\n",
    "\n",
    "**bias** I was hesitating if use *none* or *lora_only*. For text classification the most common value is none, and for chat or question answering, *all* or *lora_only*.\n",
    "\n",
    "**task_type**. Indicates the task the model is beign trained for. In this case, text generation.\n",
    "\n",
    "### Create the PEFT model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BG1zBmhsGQ-h",
    "outputId": "67a28ea2-0523-4462-a078-9b7e6e4658b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 466,944 || all params: 559,607,808 || trainable%: 0.0834\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "peft_model = get_peft_model(foundation_model, lora_config)\n",
    "print(peft_model.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2onXUsaw-Ga0"
   },
   "source": [
    "The number of trainable parameters is really small compared with the total number of parameters in the pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "HArPQ_lvGUkY"
   },
   "outputs": [],
   "source": [
    "#Create a directory to contain the Model\n",
    "import os\n",
    "working_dir = '/content/drive/MyDrive/Ironhack/Lora_Tunning_PEFT'\n",
    "\n",
    "output_directory = os.path.join(working_dir, \"peft_lab_outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWalmqWm4STo"
   },
   "source": [
    "In the TrainingArgs we inform the number of epochs we want to train, the output directory and the learning_rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ND0aJ-t6ARqD"
   },
   "outputs": [],
   "source": [
    "#Creating the TrainingArgs\n",
    "import transformers\n",
    "from transformers import TrainingArguments, Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_directory,\n",
    "    auto_find_batch_size=True, # Find a correct bvatch size that fits the size of Data.\n",
    "    learning_rate= 3e-2, # Higher learning rate than full fine-tuning.\n",
    "    num_train_epochs=2,\n",
    "    use_cpu=False,\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgxsV-iy_J_o"
   },
   "source": [
    "Now we can train the model.\n",
    "To train the model we need:\n",
    "\n",
    "\n",
    "*   The PEFT Model.\n",
    "*   The training_args\n",
    "* The Dataset\n",
    "* The result of DataCollator, the Dataset ready to be procesed in blocks.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d5j7CDdf-3gC",
    "outputId": "f5364427-5af5-40f6-d12e-9aff5aa8568e"
   },
   "outputs": [],
   "source": [
    "#!pip install -U peft transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "z5NYHqBnGZyF",
    "outputId": "caf31279-c68f-4c9b-bc6e-617bcbef16d0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:09, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14, training_loss=2.9514427185058594, metrics={'train_runtime': 11.1715, 'train_samples_per_second': 8.951, 'train_steps_per_second': 1.253, 'total_flos': 21871163621376.0, 'train_loss': 2.9514427185058594, 'epoch': 2.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This cell may take up to 15 minutes to execute.\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_sample,\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False) #This is the recommended data collator by Huggingface\n",
    ")\n",
    "\n",
    "# Define a custom loss function that accepts num_items_in_batch\n",
    "def compute_loss(model, inputs, return_outputs=False, num_items_in_batch=None): # Added num_items_in_batch\n",
    "    outputs = model(**inputs)\n",
    "    return (outputs.loss, outputs) if return_outputs else outputs.loss\n",
    "\n",
    "# Override the compute_loss method of the Trainer instance\n",
    "trainer.compute_loss = compute_loss\n",
    "\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "kEKiFdpDGgOx"
   },
   "outputs": [],
   "source": [
    "#Save the model.\n",
    "peft_model_path = os.path.join(output_directory, f\"lora_model\")\n",
    "\n",
    "trainer.model.save_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "_TAjrSWSe14q"
   },
   "outputs": [],
   "source": [
    "#Load the Model.\n",
    "loaded_model = PeftModel.from_pretrained(foundation_model,\n",
    "                                        peft_model_path,\n",
    "                                        is_trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dK--YFPR6OxH"
   },
   "source": [
    "## Inference the fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ic2Imrs4EtS_",
    "outputId": "8554efaa-e197-4580-a73b-b4eae5cbcf02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): BloomForCausalLM(\n",
       "      (transformer): BloomModel(\n",
       "        (word_embeddings): Embedding(250880, 1024)\n",
       "        (word_embeddings_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (h): ModuleList(\n",
       "          (0-23): 24 x BloomBlock(\n",
       "            (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (self_attention): BloomAttention(\n",
       "              (query_key_value): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=4, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=4, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): BloomMLP(\n",
       "              (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu_impl): BloomGelu()\n",
       "              (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=1024, out_features=250880, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Ensure the model and inputs are on the same device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loaded_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_27uvJudf03",
    "outputId": "db6939f0-3f9c-4389-9539-88b11a225ee9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:676: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I want you to act as a motivational coach. My first request is \"I need help making students feel more accountable for their efforts in achieving specific goals and objectives\", I will use my answers carefully designed tests that are helpful both at the end of each session but also before they move on with new learning']\n"
     ]
    }
   ],
   "source": [
    "input_sentences = tokenizer(\"I want you to act as a motivational coach.\", return_tensors=\"pt\").to(device)\n",
    "foundational_outputs_sentence = get_outputs(loaded_model, input_sentences, max_new_tokens=50)\n",
    "\n",
    "print(tokenizer.batch_decode(foundational_outputs_sentence, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuglE0TARewx"
   },
   "source": [
    "# **Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "IfBayqOARc13"
   },
   "outputs": [],
   "source": [
    "# Example prompts and expected outputs\n",
    "prompts = [\n",
    "    \"I want you to act as a motivational coach.\",\n",
    "    \"Give me advice on achieving my career goals.\",\n",
    "    \"How can I improve my public speaking skills?\"\n",
    "]\n",
    "\n",
    "# Ground truth responses (expected outputs)\n",
    "expected_responses = [\n",
    "    \"As a motivational coach, I recommend setting clear goals, staying positive, and practicing daily.\",\n",
    "    \"To achieve your career goals, set milestones, network with others, and continuously learn.\",\n",
    "    \"Improve public speaking by practicing regularly, seeking feedback, and observing skilled speakers.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vvr_WzyFRsma",
    "outputId": "49500927-8b50-477b-ea9a-1de718377b9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: I want you to act as a motivational coach.\n",
      "Generated Response: I want you to act as a motivational coach. My first request is \"I need some help finding motivation in my life.\" My first request is \"I need help finding motivation in my work.\" My first request is \"I need help finding motivation in my work.\" My first request is \"I need help\n",
      "\n",
      "Prompt: Give me advice on achieving my career goals.\n",
      "Generated Response: Give me advice on achieving my career goals. My first request is \"I need you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you\n",
      "\n",
      "Prompt: How can I improve my public speaking skills?\n",
      "Generated Response: How can I improve my public speaking skills? The you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generated_responses = []\n",
    "\n",
    "for prompt in prompts:\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = loaded_model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=50,\n",
    "        num_beams=5,  # Using beam search for better quality\n",
    "        early_stopping=True\n",
    "    )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    generated_responses.append(response)\n",
    "\n",
    "# Print generated responses for review\n",
    "for i, response in enumerate(generated_responses):\n",
    "    print(f\"Prompt: {prompts[i]}\")\n",
    "    print(f\"Generated Response: {response}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TEjqb-X2SDTT"
   },
   "outputs": [],
   "source": [
    "#!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131,
     "referenced_widgets": [
      "c70ca1f2df4a4441ab8c90c9475fb615",
      "e183e11461d44559aecefaa962ade471",
      "264a69ea350b467d8e18021d4f8936a7",
      "354fbab478b24ae18d59822eadadc613",
      "8b98fce06ad74cdfa796d07d3758625f",
      "2dbfcb7b95464171b3504ac43b05e661",
      "2e9ac10b414143b9a4c5350194351508",
      "2a8735e49d1e4e5782bf7c76be595976",
      "d5fc8ac4b921451ca48d201f935bfba2",
      "273806b5fd5d47218bfc9049bc5b4304",
      "2a3345bb71ef46eeb44e306f9e2efc78",
      "0db6a6b8f82f4a7c866039676454fa7a",
      "77911929df414a598f59858d52506f49",
      "80a63717cb4f46758dc2058f2f579a8d",
      "7f0e614edf03416ca98aaf0e3e2fcb2c",
      "47d4b444c62e493880312c31275585f2",
      "917ab47a5d4b43db9d0360445d4b3c4b",
      "7d0a4bc14a114cccbb2c401bebf571ed",
      "c7f747995bec4407bffe4439b306065f",
      "5596f60851a046d2bc3ac9e5f42b8947",
      "0f7033a6a02a4cc68a4abfaefbbbea5e",
      "6e3d89624b344ed0bfeb4d467aac27ab",
      "6ce2e18f38d8439aa94747b5d5cefd1e",
      "15ccc51d5ace4ef8b599645cb29dced5",
      "7aeabe9a3f854acc85af35c4bcbf0c0b",
      "6686cdaf68f8452a9bd7668ddec17855",
      "8def38cad5f6457a9aa3236e4f0f109f",
      "99a08625fc164d2f9fb7ac62fdf8b105",
      "a93d1c1e1c56473580e26e958f59e819",
      "88f2e044a8034526b1a72a16df8d57d2",
      "42a2000ee9fe4455ac3e652c0cc8c679",
      "25be8e60468d4a868c96698953684a9d",
      "7550c83acaee4e969396c42739a35479"
     ]
    },
    "id": "NLVkle6WQzDJ",
    "outputId": "ed04aadd-2e8e-4cc2-a09d-421dae8319eb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70ca1f2df4a4441ab8c90c9475fb615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db6a6b8f82f4a7c866039676454fa7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce2e18f38d8439aa94747b5d5cefd1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "#BLUE Metric Calculation\n",
    "\n",
    "from evaluate import load\n",
    "\n",
    "# Load BLEU metric\n",
    "bleu = load(\"bleu\")\n",
    "\n",
    "# Compute BLEU score\n",
    "bleu_results = bleu.compute(predictions=generated_responses, references=[[resp] for resp in expected_responses])\n",
    "print(\"BLEU Score:\", bleu_results[\"bleu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P84gZgBuSld2"
   },
   "outputs": [],
   "source": [
    "#!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "fed6ba63eece4cc48dd2aa14519342da",
      "5991d14fe66f4f589d226153b8410350",
      "991d717bea3d473b9f8eab8eb6f1ad00",
      "e714fecc0b924b90ae55f85f6e900535",
      "427d0a6fb45d4632a566258df98981d4",
      "05e632035050470185d1a615315cf52a",
      "3a18849ef083435daad014102b04b732",
      "75887d9b5592465a8a943636da571a9e",
      "9e181d548ee5488f9a0c0bd58fbff6fe",
      "f77112dc70ad44e18095a01ecbd67257",
      "b3dbefd9921b440b9f25333878a5f1b3"
     ]
    },
    "id": "z7VRNAMUSWFw",
    "outputId": "0b219f3f-9b0b-4396-8f3e-af85772b0bda"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed6ba63eece4cc48dd2aa14519342da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores: {'rouge1': 0.0971020150755278, 'rouge2': 0.050234988086650494, 'rougeL': 0.09710201507552779, 'rougeLsum': 0.0971020150755278}\n"
     ]
    }
   ],
   "source": [
    "#Rouge Metric Calculation\n",
    "\n",
    "# Load ROUGE metric\n",
    "rouge = load(\"rouge\")\n",
    "\n",
    "# Compute ROUGE scores\n",
    "rouge_results = rouge.compute(predictions=generated_responses, references=expected_responses)\n",
    "print(\"ROUGE Scores:\", rouge_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCV9JOBG6Ug8"
   },
   "source": [
    "The result is amazing. Let's compare the answer of the pre-trained Model withe the one fine-tuned by us using LoRA:\n",
    "* **Pretrained Model:** *I want you to act as a motivational coach.*  Don't be afraid of being challenged.\n",
    "* **Fine-Tuned Model:** I want you to act as a motivational coach.  I will provide some information about someone\\'s motivation and goals, but it should be your job  in order my first request – \"I need someone who can help me find the best way for myself stay motivated when competing against others.\" My suggestion is “I have\n",
    "\n",
    "As you can see the result is really similar to the samples containmed in the Datased used to fine-tune the Model. And we only trained the Model for 10 epochs and with a really small number of rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tr4Sm32y89Ji"
   },
   "source": [
    "# Exercise\n",
    "\n",
    "- Drive your own experiments with all the variables and different model types.\n",
    "    - Please with the **lora_config** values, maybe you can achieve a better result in less epochs, saving time and money for your company. :-)\n",
    "- Write a one page report\n",
    "    - What did you learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aJ0BOurTwV6"
   },
   "source": [
    "# **EXP01: Experiments with model \"bigscience/bloom-560m\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "C1UnjuGqoacP"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_exp01 = \"bigscience/bloom-560m\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_exp01)\n",
    "foundation_model = AutoModelForCausalLM.from_pretrained(model_exp01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "B0WFs1htUAhm"
   },
   "outputs": [],
   "source": [
    "#this function returns the outputs from the model received, and inputs.\n",
    "def get_outputs(model, inputs, max_new_tokens=50): #play with this function inputs and see if you get something interesting\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        repetition_penalty=1.5,\n",
    "        num_beams=5,  # Enable beam search for better quality\n",
    "        do_sample=True,  # Enable sampling\n",
    "        temperature=0.7,  # Control randomness\n",
    "        early_stopping=True, #The model can stop before reach the max_length\n",
    "        eos_token_id=tokenizer.eos_token_id # End-of-sequence token\n",
    "    )\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122,
     "referenced_widgets": [
      "c81a0a51f9a64bbc9b711606f915dde6",
      "24b9a821c51d4cc4a347c632dfd71b77",
      "5d6e8f7950434391bb24ef82cace5972",
      "a5cd3cc83ab444f19f0cbfa301114f9e",
      "3692b336ff20476787a29369d32f9288",
      "774f90868e154ef68755049961424e08",
      "0963db3db27e45759d2ddd460ddb4b16",
      "8f49f6fecc9c4817a2ef94033b0777a8",
      "1d74e3ed9fa3469996d98d2ec5d16996",
      "ea778689e02c4a769cfc4ad96ef8d511",
      "c336459facae49b0a6ef1fdb22ac316f"
     ]
    },
    "id": "srhPyP-1VT62",
    "outputId": "594a1ca3-f00d-4f74-fc91-f4f539ac2033"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81a0a51f9a64bbc9b711606f915dde6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Preparing the Dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = \"fka/awesome-chatgpt-prompts\"\n",
    "\n",
    "#Create the Dataset to create prompts.\n",
    "data_exp01 = load_dataset(dataset)\n",
    "data_exp01 = data_exp01.map(lambda samples: tokenizer(samples[\"prompt\"]), batched=True)\n",
    "train_sample_exp01 = data_exp01[\"train\"].select(range(200))\n",
    "\n",
    "train_sample_exp01 = train_sample_exp01.remove_columns('act')\n",
    "\n",
    "display(train_sample_exp01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lpz0BJJpVhQH",
    "outputId": "221a3e19-e2d9-43b7-bdeb-9070d41d6756"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': ['Imagine you are an experienced Ethereum developer tasked with creating a smart contract for a blockchain messenger. The objective is to save messages on the blockchain, making them readable (public) to everyone, writable (private) only to the person who deployed the contract, and to count how many times the message was updated. Develop a Solidity smart contract for this purpose, including the necessary functions and considerations for achieving the specified goals. Please provide the code and any relevant explanations to ensure a clear understanding of the implementation.'], 'input_ids': [[186402, 1152, 1306, 660, 72560, 28857, 167625, 84544, 20165, 376, 1002, 26168, 267, 30479, 17477, 613, 267, 120755, 238776, 17, 1387, 47881, 632, 427, 14565, 29866, 664, 368, 120755, 15, 16997, 4054, 136044, 375, 4859, 12, 427, 39839, 15, 9697, 1242, 375, 13614, 12, 3804, 427, 368, 2298, 5268, 109891, 368, 17477, 15, 530, 427, 11210, 4143, 7112, 11866, 368, 11011, 1620, 36320, 17, 21265, 267, 11550, 90533, 30479, 17477, 613, 1119, 27343, 15, 11762, 368, 18348, 16231, 530, 127246, 613, 94510, 368, 25605, 55790, 17, 29901, 13842, 368, 4400, 530, 2914, 24466, 184637, 427, 22646, 267, 11285, 32391, 461, 368, 17786, 17]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "print(train_sample_exp01[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-a46SMXD0I3T",
    "outputId": "90fd0a89-a8ef-4309-b2c4-1a5264170f5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': ['Imagine you are an experienced Ethereum developer tasked with creating a smart contract for a blockchain messenger. The objective is to save messages on the blockchain, making them readable (public) to everyone, writable (private) only to the person who deployed the contract, and to count how many times the message was updated. Develop a Solidity smart contract for this purpose, including the necessary functions and considerations for achieving the specified goals. Please provide the code and any relevant explanations to ensure a clear understanding of the implementation.', \"Using WebPilot, create an outline for an article that will be 2,000 words on the keyword 'Best SEO prompts' based on the top 10 results from Google. Include every relevant heading possible. Keep the keyword density of the headings high. For each section of the outline, include the word count. Include FAQs section in the outline too, based on people also ask section from Google for the keyword. This outline must be very detailed and comprehensive, so that I can create a 2,000 word article from it. Generate a long list of LSI and NLP keywords related to my keyword. Also include any other words related to the keyword. Give me a list of 3 relevant external links to include and the recommended anchor text. Make sure they’re not competing articles. Split the outline into part 1 and part 2.\", 'I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd', 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"', 'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conversation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"'], 'input_ids': [[186402, 1152, 1306, 660, 72560, 28857, 167625, 84544, 20165, 376, 1002, 26168, 267, 30479, 17477, 613, 267, 120755, 238776, 17, 1387, 47881, 632, 427, 14565, 29866, 664, 368, 120755, 15, 16997, 4054, 136044, 375, 4859, 12, 427, 39839, 15, 9697, 1242, 375, 13614, 12, 3804, 427, 368, 2298, 5268, 109891, 368, 17477, 15, 530, 427, 11210, 4143, 7112, 11866, 368, 11011, 1620, 36320, 17, 21265, 267, 11550, 90533, 30479, 17477, 613, 1119, 27343, 15, 11762, 368, 18348, 16231, 530, 127246, 613, 94510, 368, 25605, 55790, 17, 29901, 13842, 368, 4400, 530, 2914, 24466, 184637, 427, 22646, 267, 11285, 32391, 461, 368, 17786, 17], [39312, 15202, 51, 46712, 15, 7932, 660, 67606, 613, 660, 8723, 861, 2152, 722, 415, 15, 1874, 17848, 664, 368, 70062, 38038, 388, 174249, 39841, 9427, 11173, 664, 368, 7921, 1581, 9649, 1485, 8943, 17, 137151, 6216, 24466, 87480, 6399, 17, 109988, 368, 70062, 32993, 461, 368, 10082, 3164, 6426, 17, 5070, 5546, 13773, 461, 368, 67606, 15, 13756, 368, 14679, 11210, 17, 137151, 209147, 86, 13773, 361, 368, 67606, 10136, 15, 11173, 664, 6199, 3466, 9283, 13773, 1485, 8943, 613, 368, 70062, 17, 3904, 67606, 6591, 722, 5636, 53180, 530, 65604, 15, 1427, 861, 473, 1400, 7932, 267, 415, 15, 1874, 14679, 8723, 1485, 718, 17, 143293, 267, 3829, 4737, 461, 499, 49863, 530, 557, 103096, 135158, 17251, 427, 2670, 70062, 17, 30497, 13756, 2914, 3390, 17848, 17251, 427, 368, 70062, 17, 121045, 1074, 267, 4737, 461, 735, 24466, 26331, 31437, 427, 13756, 530, 368, 49635, 91770, 5484, 17, 42187, 11097, 3291, 87099, 1130, 174169, 14476, 17, 152830, 368, 67606, 3727, 1571, 404, 530, 1571, 415, 17], [44, 4026, 1152, 427, 1769, 661, 267, 104105, 28434, 17, 473, 2152, 4105, 49123, 530, 1152, 2152, 57502, 1002, 3595, 368, 28434, 3403, 6460, 17, 473, 4026, 1152, 427, 3804, 57502, 1002, 368, 28434, 10014, 14652, 2592, 19826, 4400, 10973, 15, 530, 16915, 4384, 17, 727, 1130, 11602, 184637, 17, 727, 1130, 4105, 49123, 35262, 473, 32247, 1152, 427, 727, 1427, 17, 3262, 707, 3423, 427, 13485, 1152, 7747, 361, 170205, 15, 707, 2152, 727, 1427, 1331, 55385, 5484, 14652, 6291, 999, 117805, 731, 29726, 1119, 96, 17, 2670, 3968, 9361, 632, 269, 42512], [44, 4026, 1152, 427, 1769, 661, 660, 7165, 242510, 15, 102509, 9428, 280, 530, 11754, 762, 17, 473, 2152, 32741, 427, 1152, 361, 2914, 16340, 530, 1152, 2152, 17859, 368, 16340, 15, 53918, 718, 530, 12300, 361, 368, 130555, 530, 44649, 6997, 461, 2670, 5484, 15, 361, 7165, 17, 473, 4026, 1152, 427, 29495, 2670, 87695, 142328, 46315, 17848, 530, 93150, 1002, 3172, 40704, 530, 104189, 15, 29923, 6626, 7165, 17848, 530, 93150, 17, 109988, 368, 30916, 5025, 15, 1965, 5219, 4054, 3172, 140624, 17, 473, 4026, 1152, 427, 3804, 57502, 368, 62948, 15, 368, 95622, 530, 16915, 4384, 15, 727, 1130, 11602, 184637, 17, 9293, 3968, 42932, 632, 567, 10928, 69, 7798, 84227, 458, 4112, 92, 333, 5967, 699, 5486, 57616, 84227, 35881, 184849], [44, 4026, 1152, 427, 1769, 661, 660, 33322, 259, 17, 473, 2152, 722, 368, 42581, 530, 1152, 2152, 9283, 1074, 368, 33322, 11732, 613, 368, 9747, 9832, 67, 8748, 17, 473, 4026, 1152, 427, 3804, 57502, 661, 368, 33322, 259, 17, 9227, 1130, 11602, 1728, 368, 56462, 919, 14275, 17, 473, 4026, 1152, 427, 3804, 727, 368, 33322, 1002, 1074, 17, 115072, 1074, 368, 11732, 530, 18688, 613, 2670, 41259, 17, 9227, 1130, 11602, 184637, 17, 115072, 1074, 368, 11732, 2592, 1331, 2592, 3269, 660, 33322, 259, 4636, 530, 18688, 613, 2670, 41259, 17, 9293, 3968, 42932, 632, 17959, 44824]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "print(train_sample_exp01[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Qbc1F9kJVkix"
   },
   "outputs": [],
   "source": [
    "#Fine-Tuning\n",
    "\n",
    "# TARGET_MODULES\n",
    "# https://github.com/huggingface/peft/blob/39ef2546d5d9b8f5f8a7016ec10657887a867041/src/peft/utils/other.py#L220\n",
    "\n",
    "import peft\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "\n",
    "lora_config_exp01 = LoraConfig(\n",
    "    r=8, #As bigger the R bigger the parameters to train. changed 4=>8\n",
    "    lora_alpha=1, # a scaling factor that adjusts the magnitude of the weight matrix.\n",
    "    target_modules=[\"query_key_value\"], #You can obtain a list of target modules in the URL above.\n",
    "    lora_dropout=0.2, #Helps to avoid Overfitting. changed 0.05=>0.1 #changed 0.1=>0.2 for exp#02\n",
    "    bias=\"lora_only\", # this specifies if the bias parameter should be trained.\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nf72MEndVrf6",
    "outputId": "b2264ec0-5a30-40f9-e575-facb72eda4aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 73,728 || all params: 559,607,808 || trainable%: 0.0132\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Create the PEFT model.\n",
    "\n",
    "peft_model_exp01 = get_peft_model(foundation_model, lora_config_exp01)\n",
    "print(peft_model.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y4n6rsWXYr8n",
    "outputId": "1d5db228-00d2-4bb0-ced1-b2c344046b5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 73,728 || all params: 560,001,024 || trainable%: 0.0132\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(peft_model_exp01.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "i-Q4wj1nVxYU"
   },
   "outputs": [],
   "source": [
    "#Create a directory to contain the Model\n",
    "import os\n",
    "working_dir = '/content/drive/MyDrive/Ironhack/Lora_Tunning_PEFT'\n",
    "\n",
    "output_directory_exp01 = os.path.join(working_dir, \"peft_lab_outputs_exp01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "1VbwwnE1V-CY"
   },
   "outputs": [],
   "source": [
    "#Creating the TrainingArgs\n",
    "import transformers\n",
    "from transformers import TrainingArguments, Trainer\n",
    "training_args_exp01 = TrainingArguments(\n",
    "    output_dir=output_directory_exp01,\n",
    "    auto_find_batch_size=True, # Find a correct bvatch size that fits the size of Data.\n",
    "    learning_rate=5e-3 , # Higher learning rate than full fine-tuning. #changed 3e-2=>5e-3 for exp#02 Reduced for a more stable training process\n",
    "    num_train_epochs=50,#changed 2=>1 #changed 1=>3 for exp#02 Increase for mor learning #changed 3=>50 for exp#03\n",
    "    use_cpu=False,\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "HhRC5KhLWBHj",
    "outputId": "e18e7b7f-e6d3-4e8c-c0be-95fc9853421f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   6/1250 00:04 < 23:29, 0.88 it/s, Epoch 0.20/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2500/2500 20:20, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>5.508800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>10.732600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>11.573300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>12.384000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>12.769400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2500, training_loss=10.59362646484375, metrics={'train_runtime': 1220.5382, 'train_samples_per_second': 8.193, 'train_steps_per_second': 2.048, 'total_flos': 2651976247246848.0, 'train_loss': 10.59362646484375, 'epoch': 50.0})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train\n",
    "\n",
    "#This cell may take up to 15 minutes to execute.\n",
    "trainer_exp01 = Trainer(\n",
    "    model=peft_model_exp01,\n",
    "    args=training_args_exp01,\n",
    "    train_dataset=train_sample_exp01,\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")\n",
    "\n",
    "# Define a custom loss function that accepts num_items_in_batch\n",
    "def compute_loss(model, inputs, return_outputs=False, num_items_in_batch=None): # Added num_items_in_batch\n",
    "    outputs = model(**inputs)\n",
    "    return (outputs.loss, outputs) if return_outputs else outputs.loss\n",
    "\n",
    "# Override the compute_loss method of the Trainer instance\n",
    "trainer_exp01.compute_loss = compute_loss\n",
    "\n",
    "trainer_exp01.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "a4sY9nQaW2Xq"
   },
   "outputs": [],
   "source": [
    "#Save the model.\n",
    "peft_model_path_exp01 = os.path.join(output_directory_exp01, f\"lora_model_exp01\")\n",
    "\n",
    "trainer_exp01.model.save_pretrained(peft_model_path_exp01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "FdV21tRpXES5"
   },
   "outputs": [],
   "source": [
    "#Load the Model.\n",
    "loaded_model_exp01 = PeftModel.from_pretrained(foundation_model,\n",
    "                                        peft_model_path_exp01,\n",
    "                                        is_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CN2AelLmbPpD",
    "outputId": "533f424b-ecc5-4af2-abdb-f191f3c16f87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): BloomForCausalLM(\n",
       "      (transformer): BloomModel(\n",
       "        (word_embeddings): Embedding(250880, 1024)\n",
       "        (word_embeddings_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (h): ModuleList(\n",
       "          (0-23): 24 x BloomBlock(\n",
       "            (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (self_attention): BloomAttention(\n",
       "              (query_key_value): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): BloomMLP(\n",
       "              (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu_impl): BloomGelu()\n",
       "              (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=1024, out_features=250880, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Ensure the model and inputs are on the same device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loaded_model_exp01.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AXpOKmOlXGSw",
    "outputId": "ed3d0c7a-5ec6-490e-f863-e0f9e8c28850"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I want you to act as a motivational coach. pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr']\n"
     ]
    }
   ],
   "source": [
    "#Inference the fine-tuned model.\n",
    "\n",
    "# Prepare the input sentence and move it to the same device as the model\n",
    "input_sentences_exp01 = tokenizer(\"I want you to act as a motivational coach.\", return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generate output using the fine-tuned model\n",
    "foundational_outputs_sentence_exp01 = get_outputs(loaded_model_exp01, input_sentences_exp01, max_new_tokens=50)\n",
    "\n",
    "# Decode and print the generated response\n",
    "print(tokenizer.batch_decode(foundational_outputs_sentence_exp01, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "bsgUGGe-SmjK"
   },
   "outputs": [],
   "source": [
    "# Example prompts and expected outputs\n",
    "prompts_exp01 = [\n",
    "    \"I want you to act as a motivational coach.\",\n",
    "    \"Give me advice on achieving my career goals.\",\n",
    "    \"How can I improve my public speaking skills?\"\n",
    "]\n",
    "\n",
    "# Ground truth responses (expected outputs)\n",
    "expected_responses_exp01 = [\n",
    "    \"As a motivational coach, I recommend setting clear goals, staying positive, and practicing daily.\",\n",
    "    \"To achieve your career goals, set milestones, network with others, and continuously learn.\",\n",
    "    \"Improve public speaking by practicing regularly, seeking feedback, and observing skilled speakers.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ejxCbiQ6SmjN",
    "outputId": "a4a9ef4f-241f-4bd3-c3c1-996bcee9764e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: I want you to act as a motivational coach.\n",
      "Generated Response: I want you to act as a motivational coach. pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr pr\n",
      "\n",
      "Prompt: Give me advice on achieving my career goals.\n",
      "Generated Response: Give me advice on achieving my career goals. and and and and and and and and and and and and and and and and and and and and and and first first first first first first first first first first first first first first first first first first first first first first first first first first first first\n",
      "\n",
      "Prompt: How can I improve my public speaking skills?\n",
      "Generated Response: How can I improve my public speaking skills? and and and and and up up up up up up up up up up up up up up up up up up up up up up up up up up up up up up up up up up up up up up up up up up up up up\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generated_responses_exp01 = []\n",
    "\n",
    "for prompt in prompts_exp01:\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = loaded_model_exp01.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=50,\n",
    "        num_beams=5,  # Using beam search for better quality\n",
    "        early_stopping=True\n",
    "    )\n",
    "    response_exp01 = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    generated_responses_exp01.append(response_exp01)\n",
    "\n",
    "# Print generated responses for review\n",
    "for i, response_exp01 in enumerate(generated_responses_exp01):\n",
    "    print(f\"Prompt: {prompts_exp01[i]}\")\n",
    "    print(f\"Generated Response: {response_exp01}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LrYiRcgISmjP",
    "outputId": "3525b8f5-5fee-4306-a4b2-9165e98c610c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "#BLUE Metric Calculation\n",
    "\n",
    "from evaluate import load\n",
    "\n",
    "# Load BLEU metric\n",
    "bleu = load(\"bleu\")\n",
    "\n",
    "# Compute BLEU score\n",
    "bleu_results_exp01 = bleu.compute(predictions=generated_responses_exp01, references=[[resp] for resp in expected_responses_exp01])\n",
    "print(\"BLEU Score:\", bleu_results_exp01[\"bleu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vZ71xphISmjR",
    "outputId": "da7c757c-769f-4bc2-b116-0fabdb588104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores: {'rouge1': 0.11192635263636615, 'rouge2': 0.04763477140192676, 'rougeL': 0.10279393254504195, 'rougeLsum': 0.10279393254504195}\n"
     ]
    }
   ],
   "source": [
    "#Rouge Metric Calculation\n",
    "\n",
    "# Load ROUGE metric\n",
    "rouge = load(\"rouge\")\n",
    "\n",
    "# Compute ROUGE scores\n",
    "rouge_results_exp01 = rouge.compute(predictions=generated_responses_exp01, references=expected_responses_exp01)\n",
    "print(\"ROUGE Scores:\", rouge_results_exp01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IGtX_egzW7ZJ"
   },
   "source": [
    "# **EXP02: Experiments by optimizing model \"bigscience/bloom-560m\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "0OUdEN9WW7ZK"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_exp02 = \"bigscience/bloom-560m\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_exp02)\n",
    "foundation_model = AutoModelForCausalLM.from_pretrained(model_exp02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "RUYHt6mPW7ZL"
   },
   "outputs": [],
   "source": [
    "#this function returns the outputs from the model received, and inputs.\n",
    "def get_outputs(model, inputs, max_new_tokens=50): #play with this function inputs and see if you get something interesting\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        repetition_penalty=1.2,# Reduced to limit excessive penalization\n",
    "        num_beams=10,  # Increased for higher-quality generations\n",
    "        do_sample=True,  # Enable sampling\n",
    "        temperature=0.5,  # Reduced to balance randomness and repetition\n",
    "        early_stopping=True, #The model can stop before reach the max_length\n",
    "        eos_token_id=tokenizer.eos_token_id # End-of-sequence token\n",
    "    )\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "OsVKCCG7W7ZM",
    "outputId": "ebfc577d-5de7-4a0b-e1ad-6ed346a837da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 203\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Preparing the Dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = \"fka/awesome-chatgpt-prompts\"\n",
    "\n",
    "#Create the Dataset to create prompts.\n",
    "data_exp02 = load_dataset(dataset)\n",
    "data_exp02 = data_exp02.map(lambda samples: tokenizer(samples[\"prompt\"]), batched=True)\n",
    "train_sample_exp02 = data_exp02[\"train\"].select(range(203))\n",
    "\n",
    "train_sample_exp02 = train_sample_exp02.remove_columns('act')\n",
    "\n",
    "display(train_sample_exp02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CFdFv-FiW7ZO",
    "outputId": "3a9826cd-2369-4228-86fd-fc446d737e48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': ['Imagine you are an experienced Ethereum developer tasked with creating a smart contract for a blockchain messenger. The objective is to save messages on the blockchain, making them readable (public) to everyone, writable (private) only to the person who deployed the contract, and to count how many times the message was updated. Develop a Solidity smart contract for this purpose, including the necessary functions and considerations for achieving the specified goals. Please provide the code and any relevant explanations to ensure a clear understanding of the implementation.'], 'input_ids': [[186402, 1152, 1306, 660, 72560, 28857, 167625, 84544, 20165, 376, 1002, 26168, 267, 30479, 17477, 613, 267, 120755, 238776, 17, 1387, 47881, 632, 427, 14565, 29866, 664, 368, 120755, 15, 16997, 4054, 136044, 375, 4859, 12, 427, 39839, 15, 9697, 1242, 375, 13614, 12, 3804, 427, 368, 2298, 5268, 109891, 368, 17477, 15, 530, 427, 11210, 4143, 7112, 11866, 368, 11011, 1620, 36320, 17, 21265, 267, 11550, 90533, 30479, 17477, 613, 1119, 27343, 15, 11762, 368, 18348, 16231, 530, 127246, 613, 94510, 368, 25605, 55790, 17, 29901, 13842, 368, 4400, 530, 2914, 24466, 184637, 427, 22646, 267, 11285, 32391, 461, 368, 17786, 17]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "print(train_sample_exp02[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QfwrYJIBW7ZP",
    "outputId": "a9ff8e40-243d-4027-fe92-a2e41dc576bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': ['Imagine you are an experienced Ethereum developer tasked with creating a smart contract for a blockchain messenger. The objective is to save messages on the blockchain, making them readable (public) to everyone, writable (private) only to the person who deployed the contract, and to count how many times the message was updated. Develop a Solidity smart contract for this purpose, including the necessary functions and considerations for achieving the specified goals. Please provide the code and any relevant explanations to ensure a clear understanding of the implementation.', \"Using WebPilot, create an outline for an article that will be 2,000 words on the keyword 'Best SEO prompts' based on the top 10 results from Google. Include every relevant heading possible. Keep the keyword density of the headings high. For each section of the outline, include the word count. Include FAQs section in the outline too, based on people also ask section from Google for the keyword. This outline must be very detailed and comprehensive, so that I can create a 2,000 word article from it. Generate a long list of LSI and NLP keywords related to my keyword. Also include any other words related to the keyword. Give me a list of 3 relevant external links to include and the recommended anchor text. Make sure they’re not competing articles. Split the outline into part 1 and part 2.\", 'I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd', 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"', 'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conversation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"'], 'input_ids': [[186402, 1152, 1306, 660, 72560, 28857, 167625, 84544, 20165, 376, 1002, 26168, 267, 30479, 17477, 613, 267, 120755, 238776, 17, 1387, 47881, 632, 427, 14565, 29866, 664, 368, 120755, 15, 16997, 4054, 136044, 375, 4859, 12, 427, 39839, 15, 9697, 1242, 375, 13614, 12, 3804, 427, 368, 2298, 5268, 109891, 368, 17477, 15, 530, 427, 11210, 4143, 7112, 11866, 368, 11011, 1620, 36320, 17, 21265, 267, 11550, 90533, 30479, 17477, 613, 1119, 27343, 15, 11762, 368, 18348, 16231, 530, 127246, 613, 94510, 368, 25605, 55790, 17, 29901, 13842, 368, 4400, 530, 2914, 24466, 184637, 427, 22646, 267, 11285, 32391, 461, 368, 17786, 17], [39312, 15202, 51, 46712, 15, 7932, 660, 67606, 613, 660, 8723, 861, 2152, 722, 415, 15, 1874, 17848, 664, 368, 70062, 38038, 388, 174249, 39841, 9427, 11173, 664, 368, 7921, 1581, 9649, 1485, 8943, 17, 137151, 6216, 24466, 87480, 6399, 17, 109988, 368, 70062, 32993, 461, 368, 10082, 3164, 6426, 17, 5070, 5546, 13773, 461, 368, 67606, 15, 13756, 368, 14679, 11210, 17, 137151, 209147, 86, 13773, 361, 368, 67606, 10136, 15, 11173, 664, 6199, 3466, 9283, 13773, 1485, 8943, 613, 368, 70062, 17, 3904, 67606, 6591, 722, 5636, 53180, 530, 65604, 15, 1427, 861, 473, 1400, 7932, 267, 415, 15, 1874, 14679, 8723, 1485, 718, 17, 143293, 267, 3829, 4737, 461, 499, 49863, 530, 557, 103096, 135158, 17251, 427, 2670, 70062, 17, 30497, 13756, 2914, 3390, 17848, 17251, 427, 368, 70062, 17, 121045, 1074, 267, 4737, 461, 735, 24466, 26331, 31437, 427, 13756, 530, 368, 49635, 91770, 5484, 17, 42187, 11097, 3291, 87099, 1130, 174169, 14476, 17, 152830, 368, 67606, 3727, 1571, 404, 530, 1571, 415, 17], [44, 4026, 1152, 427, 1769, 661, 267, 104105, 28434, 17, 473, 2152, 4105, 49123, 530, 1152, 2152, 57502, 1002, 3595, 368, 28434, 3403, 6460, 17, 473, 4026, 1152, 427, 3804, 57502, 1002, 368, 28434, 10014, 14652, 2592, 19826, 4400, 10973, 15, 530, 16915, 4384, 17, 727, 1130, 11602, 184637, 17, 727, 1130, 4105, 49123, 35262, 473, 32247, 1152, 427, 727, 1427, 17, 3262, 707, 3423, 427, 13485, 1152, 7747, 361, 170205, 15, 707, 2152, 727, 1427, 1331, 55385, 5484, 14652, 6291, 999, 117805, 731, 29726, 1119, 96, 17, 2670, 3968, 9361, 632, 269, 42512], [44, 4026, 1152, 427, 1769, 661, 660, 7165, 242510, 15, 102509, 9428, 280, 530, 11754, 762, 17, 473, 2152, 32741, 427, 1152, 361, 2914, 16340, 530, 1152, 2152, 17859, 368, 16340, 15, 53918, 718, 530, 12300, 361, 368, 130555, 530, 44649, 6997, 461, 2670, 5484, 15, 361, 7165, 17, 473, 4026, 1152, 427, 29495, 2670, 87695, 142328, 46315, 17848, 530, 93150, 1002, 3172, 40704, 530, 104189, 15, 29923, 6626, 7165, 17848, 530, 93150, 17, 109988, 368, 30916, 5025, 15, 1965, 5219, 4054, 3172, 140624, 17, 473, 4026, 1152, 427, 3804, 57502, 368, 62948, 15, 368, 95622, 530, 16915, 4384, 15, 727, 1130, 11602, 184637, 17, 9293, 3968, 42932, 632, 567, 10928, 69, 7798, 84227, 458, 4112, 92, 333, 5967, 699, 5486, 57616, 84227, 35881, 184849], [44, 4026, 1152, 427, 1769, 661, 660, 33322, 259, 17, 473, 2152, 722, 368, 42581, 530, 1152, 2152, 9283, 1074, 368, 33322, 11732, 613, 368, 9747, 9832, 67, 8748, 17, 473, 4026, 1152, 427, 3804, 57502, 661, 368, 33322, 259, 17, 9227, 1130, 11602, 1728, 368, 56462, 919, 14275, 17, 473, 4026, 1152, 427, 3804, 727, 368, 33322, 1002, 1074, 17, 115072, 1074, 368, 11732, 530, 18688, 613, 2670, 41259, 17, 9227, 1130, 11602, 184637, 17, 115072, 1074, 368, 11732, 2592, 1331, 2592, 3269, 660, 33322, 259, 4636, 530, 18688, 613, 2670, 41259, 17, 9293, 3968, 42932, 632, 17959, 44824]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "print(train_sample_exp02[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "-BvNY7DdW7ZQ"
   },
   "outputs": [],
   "source": [
    "#Fine-Tuning\n",
    "\n",
    "# TARGET_MODULES\n",
    "# https://github.com/huggingface/peft/blob/39ef2546d5d9b8f5f8a7016ec10657887a867041/src/peft/utils/other.py#L220\n",
    "\n",
    "import peft\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "\n",
    "lora_config_exp02 = LoraConfig(\n",
    "    r=16, #As bigger the R bigger the parameters to train. changed 8=>16 Increased for more parameters to train\n",
    "    lora_alpha=0.5, # a scaling factor that adjusts the magnitude of the weight matrix.  # Reduced for finer adjustments 1=>0.5\n",
    "    target_modules=[\"query_key_value\"], #You can obtain a list of target modules in the URL above.\n",
    "    lora_dropout=0.1, #Helps to avoid Overfitting.  0.1=>0.2 changed #changed 0.2=>0.1 for exp#02\n",
    "    bias=\"lora_only\", # this specifies if the bias parameter should be trained.\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dZQBQZcsW7ZQ",
    "outputId": "471d6ba1-e238-4794-b9ed-b466246f2a64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,646,592 || all params: 560,787,456 || trainable%: 0.2936\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Create the PEFT model.\n",
    "\n",
    "peft_model_exp02 = get_peft_model(foundation_model, lora_config_exp02)\n",
    "print(peft_model_exp02.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "UjB92l3lW7ZR"
   },
   "outputs": [],
   "source": [
    "#Create a directory to contain the Model\n",
    "import os\n",
    "working_dir = '/content/drive/MyDrive/Ironhack/Lora_Tunning_PEFT'\n",
    "\n",
    "output_directory_exp02 = os.path.join(working_dir, \"peft_lab_outputs_exp02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "1mQvd0LBW7ZS"
   },
   "outputs": [],
   "source": [
    "#Creating the TrainingArgs\n",
    "import transformers\n",
    "from transformers import TrainingArguments, Trainer\n",
    "training_args_exp02 = TrainingArguments(\n",
    "    output_dir=output_directory_exp02,\n",
    "    auto_find_batch_size=True, # Find a correct bvatch size that fits the size of Data.\n",
    "    learning_rate=3e-4 , # Higher learning rate than full fine-tuning. #changed 3e-2=>5e-3 for exp#01 5e-3=>3e-4 for exp02\n",
    "    num_train_epochs=100,#Increase for more learning changed 2=>50 for exp#01 changed 50=>100 for exp#02\n",
    "    use_cpu=False,\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 855
    },
    "id": "7Yyqf3UNW7ZT",
    "outputId": "d66d78e1-3bc1-48a6-fdbf-396535b0eba7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='2600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   3/2600 00:01 < 59:22, 0.73 it/s, Epoch 0.08/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='5100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  44/5100 00:20 < 40:50, 2.06 it/s, Epoch 0.84/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10200' max='10200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10200/10200 37:34, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.744500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.603800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.626700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.636300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.678900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.672700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>2.649400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.648900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>2.614200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.599500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>2.587200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.561600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>2.550700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.516600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>2.523600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.535400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>2.500900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.471900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>2.473400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.461100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10200, training_loss=2.5807017666685814, metrics={'train_runtime': 2254.774, 'train_samples_per_second': 9.003, 'train_steps_per_second': 4.524, 'total_flos': 4460804049002496.0, 'train_loss': 2.5807017666685814, 'epoch': 100.0})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train - This cell may take up to 15 minutes to execute.\n",
    "trainer_exp02 = Trainer(\n",
    "    model=peft_model_exp02,\n",
    "    args=training_args_exp02,\n",
    "    train_dataset=train_sample_exp02,\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")\n",
    "\n",
    "# Define a custom loss function that accepts num_items_in_batch\n",
    "def compute_loss(model, inputs, return_outputs=False, num_items_in_batch=None): # Added num_items_in_batch\n",
    "    outputs = model(**inputs)\n",
    "    return (outputs.loss, outputs) if return_outputs else outputs.loss\n",
    "\n",
    "# Override the compute_loss method of the Trainer instance\n",
    "trainer_exp02.compute_loss = compute_loss\n",
    "\n",
    "trainer_exp02.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "v0zECnF0W7ZU"
   },
   "outputs": [],
   "source": [
    "#Save the model.\n",
    "peft_model_path_exp02 = os.path.join(output_directory_exp02, f\"lora_model_exp02\")\n",
    "\n",
    "trainer_exp02.model.save_pretrained(peft_model_path_exp02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "Sha2WV2dW7ZU"
   },
   "outputs": [],
   "source": [
    "#Load the Model.\n",
    "loaded_model_exp02 = PeftModel.from_pretrained(foundation_model,\n",
    "                                        peft_model_path_exp02,\n",
    "                                        is_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47B-jLqHW7ZV",
    "outputId": "ca7166c1-3008-41de-e5b2-0a7a8692318b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): BloomForCausalLM(\n",
       "      (transformer): BloomModel(\n",
       "        (word_embeddings): Embedding(250880, 1024)\n",
       "        (word_embeddings_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (h): ModuleList(\n",
       "          (0-23): 24 x BloomBlock(\n",
       "            (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (self_attention): BloomAttention(\n",
       "              (query_key_value): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): BloomMLP(\n",
       "              (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu_impl): BloomGelu()\n",
       "              (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=1024, out_features=250880, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Ensure the model and inputs are on the same device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loaded_model_exp02.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4WGCBgW_W7ZW",
    "outputId": "7654b9f4-adb8-480b-994e-9df816ace59a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I want you to act as a motivational coach. I will provide you with some information related to my goals and objectives, and it will be your job to guide me through the steps I need to take to achieve them. This could involve providing advice on improving my work habits, improving my communication skills,']\n"
     ]
    }
   ],
   "source": [
    "#Inference the fine-tuned model.\n",
    "\n",
    "# Prepare the input sentence and move it to the same device as the model\n",
    "input_sentences_exp02 = tokenizer(\"I want you to act as a motivational coach.\", return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generate output using the fine-tuned model\n",
    "foundational_outputs_sentence_exp02 = get_outputs(loaded_model_exp02, input_sentences_exp02, max_new_tokens=50)\n",
    "\n",
    "# Decode and print the generated response\n",
    "print(tokenizer.batch_decode(foundational_outputs_sentence_exp02, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "CP6Lmbv_W7ZX"
   },
   "outputs": [],
   "source": [
    "# Example prompts and expected outputs\n",
    "prompts_exp02 = [\n",
    "    \"Act as a motivational coach. Provide clear and actionable advice for overcoming challenges at work.\",\n",
    "    \"What are the best strategies to set and achieve professional goals effectively?\",\n",
    "    \"How can I build confidence and enhance my public speaking skills for high-pressure situations?\"\n",
    "]\n",
    "\n",
    "# Ground truth responses (expected outputs)\n",
    "expected_responses_exp02 = [\n",
    "    \"As a motivational coach, I recommend setting clear goals, staying positive, and practicing daily.\",\n",
    "    \"To achieve your career goals, set milestones, network with others, and continuously learn.\",\n",
    "    \"Improve public speaking by practicing regularly, seeking feedback, and observing skilled speakers.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ymiwLbHvW7ZX",
    "outputId": "618d5b6b-124d-47c5-d773-c885b1080788"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Act as a motivational coach. Provide clear and actionable advice for overcoming challenges at work.\n",
      "Generated Response: Act as a motivational coach. Provide clear and actionable advice for overcoming challenges at work. Develop strategies to motivate employees to achieve their goals. Ask questions such as “How can I improve my productivity?” or “How can I overcome obstacles in my career?” My first suggestion request is “I need help focusing on improving my communication skills.” Answer: “Use the power of positive self-talk when communicating with others.” My second suggestion request is “I need help focusing on improving my leadership skills.” Answer: “Use the power of self-expression when communicating with others.”\n",
      "\n",
      "Prompt: What are the best strategies to set and achieve professional goals effectively?\n",
      "Generated Response: What are the best strategies to set and achieve professional goals effectively? What are the key factors that influence your success in achieving these goals? How do you develop a plan of action based on what you know about yourself, your strengths and weaknesses, and how you can implement it into your day-to-day life? These are some of the topics covered by this session. Join us for an interactive session where we will share our experiences with other professionals who have successfully achieved their professional goals. This session is open to anyone who is interested in learning more about specific topics related to\n",
      "\n",
      "Prompt: How can I build confidence and enhance my public speaking skills for high-pressure situations?\n",
      "Generated Response: How can I build confidence and enhance my public speaking skills for high-pressure situations? Here are some tips to help you achieve this goal. 1. Introduce yourself in a way that makes it easy for others to relate to you. For example, if someone asks you what your background is or what kind of work you do, ask them how they can relate to you. 2. Provide feedback on your ability to communicate effectively when communicating with others. Ask them questions such as “Can you say something like this?” or “Can you explain something like this?” 3.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generated_responses_exp02 = []\n",
    "\n",
    "for prompt in prompts_exp02:\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = loaded_model_exp02.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=100,  # Allow longer responses\n",
    "        num_beams=5,  # Enable beam search\n",
    "        temperature=0.8,  # Increase diversity\n",
    "        repetition_penalty=2.5,  # Penalize repetitive outputs\n",
    "        early_stopping=True,\n",
    "        do_sample=True\n",
    "    )\n",
    "    response_exp02 = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    generated_responses_exp02.append(response_exp02)\n",
    "\n",
    "# Print generated responses for review\n",
    "for i, response_exp02 in enumerate(generated_responses_exp02):\n",
    "    print(f\"Prompt: {prompts_exp02[i]}\")\n",
    "    print(f\"Generated Response: {response_exp02}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CAUOX4rIW7ZY",
    "outputId": "02ab05b2-d0fc-4909-a88b-f782bf532d89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "#BLUE Metric Calculation\n",
    "\n",
    "from evaluate import load\n",
    "\n",
    "# Load BLEU metric\n",
    "bleu = load(\"bleu\")\n",
    "\n",
    "# Compute BLEU score\n",
    "bleu_results_exp02 = bleu.compute(predictions=generated_responses_exp02, references=[[resp] for resp in expected_responses_exp02])\n",
    "print(\"BLEU Score:\", bleu_results_exp02[\"bleu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gAgrjMuvW7ZZ",
    "outputId": "20aabd90-46da-4e34-f0b8-94c096ecf6a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores: {'rouge1': 0.11934600239684985, 'rouge2': 0.025040764034474722, 'rougeL': 0.08964028229564952, 'rougeLsum': 0.08964028229564952}\n"
     ]
    }
   ],
   "source": [
    "#Rouge Metric Calculation\n",
    "\n",
    "# Load ROUGE metric\n",
    "rouge = load(\"rouge\")\n",
    "\n",
    "# Compute ROUGE scores\n",
    "rouge_results_exp02 = rouge.compute(predictions=generated_responses_exp02, references=expected_responses_exp02)\n",
    "print(\"ROUGE Scores:\", rouge_results_exp02)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMUp4gMg1UYr"
   },
   "source": [
    "# **EXP03: Experiments with GPT-4 model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "131p_dYj2AtH"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "from google.colab import userdata\n",
    "\n",
    "# Set up the OpenAI API key\n",
    "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "liGboStc3WkA"
   },
   "outputs": [],
   "source": [
    "# Example prompts and expected outputs\n",
    "prompts_exp03 = [\n",
    "    \"Act as a motivational coach. Provide clear and actionable advice for overcoming challenges at work.\",\n",
    "    \"What are the best strategies to set and achieve professional goals effectively?\",\n",
    "    \"How can I build confidence and enhance my public speaking skills for high-pressure situations?\"\n",
    "]\n",
    "\n",
    "# Ground truth responses (expected outputs)\n",
    "expected_responses_exp03 = [\n",
    "    \"As a motivational coach, I recommend setting clear goals, staying positive, and practicing daily.\",\n",
    "    \"To achieve your career goals, set milestones, network with others, and continuously learn.\",\n",
    "    \"Improve public speaking by practicing regularly, seeking feedback, and observing skilled speakers.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "jvTpt7wK5Mrb"
   },
   "outputs": [],
   "source": [
    "# Parameters for GPT-4 generation\n",
    "model_name = \"gpt-4\"\n",
    "max_tokens = 150  # Allow sufficient length for detailed responses\n",
    "temperature = 0.7  # Balance between creativity and determinism\n",
    "top_p = 1.0  # Use nucleus sampling with full probability mass\n",
    "frequency_penalty = 0.0  # No penalty for repeating words\n",
    "presence_penalty = 0.0  # No penalty for introducing new topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "eCJZJ1ORAEsB"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KfXLlnao5Tlh",
    "outputId": "9e8786ac-8d4d-4809-d0fb-23be0a363721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Act as a motivational coach. Provide clear and actionable advice for overcoming challenges at work.\n",
      "Generated Response: 1. Set Clear Goals: Establish what you want to achieve and set measurable goals. Break down your ultimate goal into smaller, manageable tasks and prioritize them. \n",
      "\n",
      "2. Stay Positive: Maintain a positive attitude even when faced with challenges. Negative thinking can not only bring you down but also affect those around you. \n",
      "\n",
      "3. Stay Focused: Distractions are everywhere, but you must remain focused on your tasks and goals. Practice time-management techniques to help you stay on track.\n",
      "\n",
      "4. Seek Help When Needed: Don't be afraid to ask for help. If you're struggling with a task, reach out to a colleague or supervisor for assistance. \n",
      "\n",
      "5. Take Breaks: Regular breaks can help to refresh your mind, boost creativity and\n",
      "\n",
      "Prompt: What are the best strategies to set and achieve professional goals effectively?\n",
      "Generated Response: 1. Set Clear and Specific Goals: The first step in achieving professional goals is to define exactly what you want. Your goals should be specific, measurable, achievable, relevant, and time-bound (SMART). \n",
      "\n",
      "2. Prioritize Your Goals: Not all goals are created equal. Some are more important than others. Prioritize your goals based on their importance and potential impact on your career.\n",
      "\n",
      "3. Break Down Bigger Goals into Smaller Tasks: Large goals can be overwhelming. Break them down into smaller, manageable tasks and set a timeline for each task.\n",
      "\n",
      "4. Develop a Plan: Create a step-by-step plan that outlines the actions you need to take to achieve your goals. This will serve as your roadmap to success.\n",
      "\n",
      "5. Stay Mot\n",
      "\n",
      "Prompt: How can I build confidence and enhance my public speaking skills for high-pressure situations?\n",
      "Generated Response: 1. Practice Regularly: The more you practice speaking in public, the better you will become at it. Start small by speaking in front of friends or family, then gradually increase the size of your audience.\n",
      "\n",
      "2. Know Your Material: The more familiar you are with your subject matter, the more confident you will be. Spend time researching and understanding the topic you're speaking about.\n",
      "\n",
      "3. Work on Your Body Language: Your body language can communicate a lot about your confidence level. Stand tall, make eye contact, and use gestures to emphasize points.\n",
      "\n",
      "4. Practice Deep Breathing: Deep breathing can help to calm your nerves before and during your speech. It can also help to improve your focus.\n",
      "\n",
      "5. Visualize Success: Spend time visual\n",
      "\n",
      "Generated responses saved to /content/drive/MyDrive/Ironhack/Lora_Tunning_PEFT/generated_responses_exp03.json\n"
     ]
    }
   ],
   "source": [
    "# List to store the generated responses\n",
    "generated_responses_exp03 = []\n",
    "\n",
    "# Iterate through the prompts and generate responses\n",
    "# Extract and store the text response\n",
    "for prompt in prompts_exp03:\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty\n",
    "    )\n",
    "\n",
    "    # Convert the response object to a dictionary\n",
    "    response_dict = response.to_dict()\n",
    "\n",
    "    # Extract the generated content and store it\n",
    "    generated_responses_exp03.append(response_dict[\"choices\"][0][\"message\"][\"content\"].strip())\n",
    "\n",
    "# Print the generated responses for review\n",
    "for i, response in enumerate(generated_responses_exp03):\n",
    "    print(f\"Prompt: {prompts_exp03[i]}\")\n",
    "    print(f\"Generated Response: {response}\\n\")\n",
    "\n",
    "# Save the results to a JSON file\n",
    "output_path = '/content/drive/MyDrive/Ironhack/Lora_Tunning_PEFT/generated_responses_exp03.json'\n",
    "with open(output_path, 'w') as json_file:\n",
    "    json.dump({\"prompts\": prompts_exp03, \"responses\": generated_responses_exp03}, json_file, indent=4)\n",
    "\n",
    "print(f\"Generated responses saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7L1biX0n1UYy",
    "outputId": "986324e0-ebef-4c7e-f8dd-c55573e47aaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "#BLUE Metric Calculation\n",
    "from evaluate import load\n",
    "\n",
    "# Load BLEU metric\n",
    "bleu = load(\"bleu\")\n",
    "\n",
    "# Compute BLEU score\n",
    "bleu_results_exp03 = bleu.compute(predictions=generated_responses_exp03, references=[[resp] for resp in expected_responses_exp03])\n",
    "print(\"BLEU Score:\", bleu_results_exp03[\"bleu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FJqEyyqB1UYz",
    "outputId": "0d4aeaa6-8406-4dc7-c13a-a9d9d3da3440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores: {'rouge1': 0.09390411775544934, 'rouge2': 0.020164046479835954, 'rougeL': 0.05933459066324153, 'rougeLsum': 0.07912507180871242}\n"
     ]
    }
   ],
   "source": [
    "#Rouge Metric Calculation\n",
    "\n",
    "# Load ROUGE metric\n",
    "rouge = load(\"rouge\")\n",
    "\n",
    "# Compute ROUGE scores\n",
    "rouge_results_exp03 = rouge.compute(predictions=generated_responses_exp03, references=expected_responses_exp03)\n",
    "print(\"ROUGE Scores:\", rouge_results_exp03)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vk0xd-KpFWTW"
   },
   "source": [
    "# **EXP04: Experiments with optimizations using GPT-4 model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "6zUj0RUGEjFw"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "from evaluate import load\n",
    "\n",
    "# Set up OpenAI API key\n",
    "from google.colab import userdata\n",
    "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "G04ibhsNFTnj"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "dREmbUJbFfPV"
   },
   "outputs": [],
   "source": [
    "# Prompts for GPT-4\n",
    "prompts_exp04 = [\n",
    "    \"As a motivational coach, provide actionable steps to overcome work challenges effectively.\",\n",
    "    \"What are the most effective methods for setting and achieving professional goals?\",\n",
    "    \"How can I improve confidence and public speaking skills for high-pressure situations?\"\n",
    "]\n",
    "\n",
    "# Ground truth responses (expected outputs)\n",
    "expected_responses_exp04 = [\n",
    "    \"To overcome work challenges, set clear goals, prioritize tasks, and seek help when needed.\",\n",
    "    \"Use SMART criteria to define goals, create action plans, and track progress regularly.\",\n",
    "    \"Practice public speaking, seek feedback, and focus on controlled breathing for confidence.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "B1Wa36hyFvun"
   },
   "outputs": [],
   "source": [
    "# Parameters for GPT-4\n",
    "model_name = \"gpt-4\"\n",
    "max_tokens = 200  # Allow for detailed responses\n",
    "temperature = 0.5  # Ensure focused and consistent responses\n",
    "top_p = 0.9  # Balance between determinism and creativity\n",
    "frequency_penalty = 0.2  # Slightly penalize repetitive phrases\n",
    "presence_penalty = 0.3  # Encourage introducing new ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S1Bk9DETEtxJ",
    "outputId": "ba8c7091-0a3b-43ad-947a-7041fadd131d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: As a motivational coach, provide actionable steps to overcome work challenges effectively.\n",
      "Generated Response: 1. Practice Regularly: The more you practice speaking in public, the better you will become at it. Start small by speaking in front of friends or family, then gradually increase the size of your audience.\n",
      "\n",
      "2. Know Your Material: The more familiar you are with your subject matter, the more confident you will be. Spend time researching and understanding the topic you're speaking about.\n",
      "\n",
      "3. Work on Your Body Language: Your body language can communicate a lot about your confidence level. Stand tall, make eye contact, and use gestures to emphasize points.\n",
      "\n",
      "4. Practice Deep Breathing: Deep breathing can help to calm your nerves before and during your speech. It can also help to improve your focus.\n",
      "\n",
      "5. Visualize Success: Spend time visual\n",
      "\n",
      "Prompt: What are the most effective methods for setting and achieving professional goals?\n",
      "Generated Response: 1. Practice Regularly: The more you practice speaking in public, the better you will become at it. Start small by speaking in front of friends or family, then gradually increase the size of your audience.\n",
      "\n",
      "2. Know Your Material: The more familiar you are with your subject matter, the more confident you will be. Spend time researching and understanding the topic you're speaking about.\n",
      "\n",
      "3. Work on Your Body Language: Your body language can communicate a lot about your confidence level. Stand tall, make eye contact, and use gestures to emphasize points.\n",
      "\n",
      "4. Practice Deep Breathing: Deep breathing can help to calm your nerves before and during your speech. It can also help to improve your focus.\n",
      "\n",
      "5. Visualize Success: Spend time visual\n",
      "\n",
      "Prompt: How can I improve confidence and public speaking skills for high-pressure situations?\n",
      "Generated Response: 1. Practice Regularly: The more you practice speaking in public, the better you will become at it. Start small by speaking in front of friends or family, then gradually increase the size of your audience.\n",
      "\n",
      "2. Know Your Material: The more familiar you are with your subject matter, the more confident you will be. Spend time researching and understanding the topic you're speaking about.\n",
      "\n",
      "3. Work on Your Body Language: Your body language can communicate a lot about your confidence level. Stand tall, make eye contact, and use gestures to emphasize points.\n",
      "\n",
      "4. Practice Deep Breathing: Deep breathing can help to calm your nerves before and during your speech. It can also help to improve your focus.\n",
      "\n",
      "5. Visualize Success: Spend time visual\n",
      "\n",
      "Generated responses saved to /content/drive/MyDrive/Ironhack/Lora_Tunning_PEFT/generated_responses_exp04.json\n"
     ]
    }
   ],
   "source": [
    "# List to store generated responses\n",
    "generated_responses_exp04 = []\n",
    "\n",
    "# Generate responses\n",
    "for prompt in prompts_exp04:\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty\n",
    "    )\n",
    "    # Extract text response\n",
    "    generated_responses_exp04.append(response_dict[\"choices\"][0][\"message\"][\"content\"].strip())\n",
    "\n",
    "# Print generated responses for review\n",
    "for i, response in enumerate(generated_responses_exp04):\n",
    "    print(f\"Prompt: {prompts_exp04[i]}\")\n",
    "    print(f\"Generated Response: {response}\\n\")\n",
    "\n",
    "# Save responses to JSON\n",
    "output_path = '/content/drive/MyDrive/Ironhack/Lora_Tunning_PEFT/generated_responses_exp04.json'\n",
    "with open(output_path, 'w') as json_file:\n",
    "    json.dump({\"prompts\": prompts_exp04, \"responses\": generated_responses_exp04}, json_file, indent=4)\n",
    "\n",
    "print(f\"Generated responses saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rSn0IVg1Gogf"
   },
   "outputs": [],
   "source": [
    "#!pip install bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355,
     "referenced_widgets": [
      "42ef79552fed419199269748f53c1ebe",
      "e19a0ec223c349b39581a9c71651f189",
      "12153ec6ffbd40dfa1c86477314438ec",
      "6a0e0d61126c44f7ac845bc1c3669546",
      "81628de9c3fe4e25a01002070cb9819d",
      "f2423a5a792d4546b42144e413a18405",
      "5a3dd23da65f48dda99e2e46ce447bcd",
      "1f956020593944628b2a9f108fee4b3f",
      "4be3c071b2ea4674be58976d0eae098a",
      "31292df008e549cb9639ad475dc13c0d",
      "680850960d1c423582929cc27e89d3f0",
      "e225cbf0242b465fa5156c4e26dca1ef",
      "369d588858ac4241a129786506ee0e5c",
      "4973a1c7b3664eab8bf3f479bd908b04",
      "30654f03b0d44278967543ad0a91683c",
      "dcafc78aa9e8421b9dfc9400f544afbf",
      "9ddd58d9d8fe4c19a4eaf75de6810726",
      "1c6e102e6fa64872a9e530ab714a38ae",
      "b0b5f4eb26fd43058d4e98774546b6dd",
      "e83f63e4dfd3478abe6651e50006941f",
      "c904af7ae76d4508b44c5baa5291d87a",
      "96bc16b7c669400a805df3e98e9de40f",
      "66cb9ebd67df4ff688a4b0de5eedf1fd",
      "bbe2d45f4daf486d8563b2e7e2b7263e",
      "e48939ffb41e49de8ebc08a88bc86215",
      "8ef1b9ab74c648c48d887586d8e00c94",
      "9209d6a1132e422f97d13607db5415ba",
      "41405b3f3fcd4738a057ab6fd194f01d",
      "ab79477865a2472c9ea5eb46fa864f5e",
      "afe0f4e6930643fc9818b210e7d67bf8",
      "5f050946900b427288467332487e8790",
      "6e6bac4a85614648abcfa756f3282a79",
      "520d6e5ee91245b49e24a24ba94cc6eb",
      "0f336a47e3144deea6b4b781624f6879",
      "0265e646df9740a4a8cbc67f6668ff37",
      "54d28b03b2d74b548836d9a1eb28bc7a",
      "66b4679853554256938f26fda42feaac",
      "fb20d59bcf1941caa0b166101472cc32",
      "0fe7edc171af41a383629e4004686408",
      "5ab6b00904a54b17b7bd9598f536dbae",
      "a6d86b99ab31417fb7fddbee678bde5d",
      "c6ea71dc470645c287abb35c6076696c",
      "294986c32c474f07b2da2ed5cd754cec",
      "f7f29ae1463244d1a9793bb82bfaa7ca",
      "4c949815c9d245c6af3bf329cbb5e801",
      "be3ec492445447e1b8cc95a0bd5bc02c",
      "769ae4e48e504d87bfbdfa36ec1614fb",
      "ce617425772a464c94dc24c84a446a59",
      "3e4269bfcfa94d0fab397dfde02e5dce",
      "70f14e6c997e450199dbfbe42272d0cb",
      "8653d8faf15b4794810e6efb19e7e415",
      "09a42adb77e44429a06b0d22093e45b9",
      "72dd4b9f82ac4d26822d7d84bd0b05bc",
      "dfa192c1398b499cb6b6da15c4600495",
      "8aec2a2cb7ae4eaa8cfb54607873cc8a",
      "75c3c75255aa42d59f0ba86707211791",
      "655d4c402d814fd684d860e119f088c0",
      "19bd1d7a24bc4da5a4038fac1b8fd6e5",
      "6555c35f2a324e99baa17fa22c52335f",
      "4f4d3d1bd8614042af4775654dd1c026",
      "d3417018a6d44e3aa806b1ee8f25510f",
      "edefab21c1464a0792789a4beb56f5b2",
      "433e112f7aa442f199d660213a59112a",
      "aafe78aa3d5d4f79b616a5134b75ecc0",
      "641f4f5d2cde4ed0bf5bcdc990d4f722",
      "e90bb76d9dc744899d379c976dd3ed64"
     ]
    },
    "id": "p9I0nHKtF2zd",
    "outputId": "0c3c8a77-0ea0-47e1-f4c6-7c943fd7225c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.0\n",
      "ROUGE Scores: {'rouge1': 0.07800407796674154, 'rouge2': 0.0, 'rougeL': 0.05850305847505616, 'rougeLsum': 0.07310211718242783}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ef79552fed419199269748f53c1ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e225cbf0242b465fa5156c4e26dca1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66cb9ebd67df4ff688a4b0de5eedf1fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f336a47e3144deea6b4b781624f6879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c949815c9d245c6af3bf329cbb5e801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c3c75255aa42d59f0ba86707211791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore Results:\n",
      "Precision: [0.8099603652954102, 0.8113323450088501, 0.8259896039962769]\n",
      "Recall: [0.8539235591888428, 0.8553771376609802, 0.8930785655975342]\n",
      "F1: [0.8313611745834351, 0.8327727913856506, 0.8582249879837036]\n"
     ]
    }
   ],
   "source": [
    "# **Evaluation Metrics**\n",
    "\n",
    "# Preprocess text: normalize case, remove punctuation, etc.\n",
    "def preprocess_text(text):\n",
    "    return text.lower().replace(\".\", \"\").replace(\",\", \"\").strip()\n",
    "\n",
    "# Preprocess responses\n",
    "processed_generated = [preprocess_text(r) for r in generated_responses_exp04]\n",
    "processed_expected = [preprocess_text(r) for r in expected_responses_exp04]\n",
    "\n",
    "# **Compute BLEU**\n",
    "bleu = load(\"bleu\")\n",
    "bleu_results_exp04 = bleu.compute(predictions=processed_generated, references=[[resp] for resp in processed_expected])\n",
    "print(\"BLEU Score:\", bleu_results_exp04[\"bleu\"])\n",
    "\n",
    "# **Compute ROUGE**\n",
    "rouge = load(\"rouge\")\n",
    "rouge_results_exp04 = rouge.compute(predictions=processed_generated, references=processed_expected)\n",
    "print(\"ROUGE Scores:\", rouge_results_exp04)\n",
    "\n",
    "# **Compute BERTScore**\n",
    "bertscore = load(\"bertscore\")\n",
    "bertscore_results_exp04 = bertscore.compute(predictions=generated_responses_exp04, references=expected_responses_exp04, lang=\"en\")\n",
    "print(\"BERTScore Results:\")\n",
    "print(f\"Precision: {bertscore_results_exp04['precision']}\")\n",
    "print(f\"Recall: {bertscore_results_exp04['recall']}\")\n",
    "print(f\"F1: {bertscore_results_exp04['f1']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Final Report: LoRA Tuning and Model Evaluation Lab**\n",
    "\n",
    "## **1. Introduction**\n",
    "This lab focused on exploring and fine-tuning models using Low-Rank Adaptation (LoRA) techniques with Hugging Face's PEFT library. The primary goal was to enhance the performance of different language models on specific tasks and evaluate their outputs using metrics such as BLEU and ROUGE. Experiments included multiple iterations with varying hyperparameters, prompt structures, and even a shift in models.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Key Learning Points**\n",
    "- **LoRA Tuning**: LoRA is a lightweight fine-tuning method that adds trainable adapters to transformer models, enabling efficient updates without retraining the entire model.\n",
    "- **Hyperparameter Optimization**: Experimentation with key hyperparameters like learning rate, number of epochs, max tokens, temperature, and penalty values revealed how each impacts model performance.\n",
    "- **Evaluation Metrics**:\n",
    "  - **BLEU (Bilingual Evaluation Understudy)**: Measures how well a generated text matches reference responses. Consistently scored **0.0** across experiments, reflecting low similarity.\n",
    "  - **ROUGE (Recall-Oriented Understudy for Gisting Evaluation)**: Evaluates overlapping n-grams, word sequences, and word pairs. Moderate improvements were observed during optimizations.\n",
    "- **Prompt Engineering**: The structure and clarity of prompts significantly influenced the quality of model-generated responses.\n",
    "- **Switching Models**: Transitioning from Bloom-560m to GPT-4 demonstrated the importance of selecting models aligned with the task’s complexity and requirements.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Challenges Encountered**\n",
    "1. **Limited Performance of Bloom-560m**:\n",
    "   - Despite hyperparameter optimization, the model showed limited improvements, often generating repetitive and generic responses.\n",
    "   - BLEU and ROUGE metrics were low throughout, suggesting the model's limitations in adapting to the provided prompts.\n",
    "\n",
    "2. **OpenAI API Adjustments**:\n",
    "   - Transitioning to GPT-4 required updates to the API structure, particularly with the `ChatCompletion` endpoint.\n",
    "   - Configuring secure access using Colab's secrets and debugging API-related errors added to the complexity.\n",
    "\n",
    "3. **Evaluation Challenges**:\n",
    "   - The generated outputs often diverged from expected responses, making metric evaluation less straightforward.\n",
    "   - Identifying meaningful metrics for qualitative outputs posed difficulties.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Observations and Results**\n",
    "### **Experiment 1 to 3 (Bloom-560m)**\n",
    "- **Metrics**:\n",
    "  - BLEU: **0.0** (all experiments)\n",
    "  - ROUGE: Marginal improvements across iterations, with `rouge1` reaching **0.119** at its peak.\n",
    "- **Outputs**: Responses were often repetitive, lacked depth, and deviated from task-specific expectations.\n",
    "- **Optimization Efforts**: Adjustments to hyperparameters such as `max_tokens`, `temperature`, and `penalty` values improved output diversity but not overall alignment.\n",
    "\n",
    "### **Experiment 4 (GPT-4)**\n",
    "- **Metrics**:\n",
    "  - BLEU: **0.0**\n",
    "  - ROUGE: `rouge1` at **0.0939**, `rougeL` at **0.0593`.\n",
    "- **Outputs**:\n",
    "  - Responses were more coherent, structured, and aligned with prompts compared to Bloom-560m.\n",
    "  - Despite better qualitative results, metric scores remained low due to differences in phrasing and structure compared to reference responses.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Justification for Model Change**\n",
    "### Transition from Bloom-560m to GPT-4:\n",
    "1. **Performance Limitations**:\n",
    "   - Bloom-560m struggled with task-specific alignment and adaptability, producing generic responses despite fine-tuning.\n",
    "   - Metric scores indicated a lack of substantial improvement, even with hyperparameter adjustments.\n",
    "\n",
    "2. **Advantages of GPT-4**:\n",
    "   - **State-of-the-Art**: GPT-4 excels in generating contextually relevant and coherent responses.\n",
    "   - **Efficiency**: Reduced need for extensive fine-tuning, allowing focus on prompt engineering.\n",
    "   - **Versatility**: Demonstrated superior generalization and response quality for diverse tasks.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Concepts Applied**\n",
    "### **LoRA Tuning**\n",
    "- LoRA enables efficient fine-tuning by introducing trainable adapters into specific transformer layers, reducing computational overhead.\n",
    "\n",
    "### **Hyperparameter Tuning**\n",
    "- Adjustments to `learning_rate`, `num_train_epochs`, `max_tokens`, and penalties (`frequency_penalty` and `presence_penalty`) directly influenced model output quality.\n",
    "\n",
    "### **Evaluation Metrics**\n",
    "- BLEU: Focused on n-gram overlap between generated and reference texts.\n",
    "- ROUGE: Assessed overlap of n-grams, sequences, and summaries, providing insights into content similarity.\n",
    "\n",
    "### **Prompt Engineering**\n",
    "- Well-structured prompts improved the quality and relevance of generated responses, highlighting the importance of clarity and task-specific framing.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Conclusions**\n",
    "1. **Model Performance**:\n",
    "   - Bloom-560m showed limited adaptability and performance improvements despite optimization.\n",
    "   - GPT-4 delivered qualitatively superior responses, justifying the model transition.\n",
    "\n",
    "2. **Metric Limitations**:\n",
    "   - BLEU and ROUGE scores were not fully representative of qualitative improvements, emphasizing the need for complementary evaluation methods.\n",
    "\n",
    "3. **Learning Outcomes**:\n",
    "   - Effective prompt engineering and hyperparameter tuning are critical for enhancing model outputs.\n",
    "   - Model selection plays a pivotal role in achieving task-specific goals.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Future Plans**\n",
    "1. **Advanced Fine-Tuning**:\n",
    "   - Experiment with additional fine-tuning techniques, including prefix-tuning and full fine-tuning for selected layers.\n",
    "\n",
    "2. **Exploration of Metrics**:\n",
    "   - Incorporate additional evaluation metrics like METEOR or human evaluation for a more comprehensive assessment.\n",
    "\n",
    "3. **Model Comparisons**:\n",
    "   - Test additional models such as GPT-NeoX, T5, or fine-tuned versions of GPT-4 for specialized tasks.\n",
    "\n",
    "4. **Optimized Prompt Engineering**:\n",
    "   - Experiment with prompt variations to further improve response quality and task alignment.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0265e646df9740a4a8cbc67f6668ff37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0fe7edc171af41a383629e4004686408",
      "placeholder": "​",
      "style": "IPY_MODEL_5ab6b00904a54b17b7bd9598f536dbae",
      "value": "merges.txt: 100%"
     }
    },
    "05e632035050470185d1a615315cf52a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0963db3db27e45759d2ddd460ddb4b16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "09a42adb77e44429a06b0d22093e45b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0db6a6b8f82f4a7c866039676454fa7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_77911929df414a598f59858d52506f49",
       "IPY_MODEL_80a63717cb4f46758dc2058f2f579a8d",
       "IPY_MODEL_7f0e614edf03416ca98aaf0e3e2fcb2c"
      ],
      "layout": "IPY_MODEL_47d4b444c62e493880312c31275585f2"
     }
    },
    "0f336a47e3144deea6b4b781624f6879": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0265e646df9740a4a8cbc67f6668ff37",
       "IPY_MODEL_54d28b03b2d74b548836d9a1eb28bc7a",
       "IPY_MODEL_66b4679853554256938f26fda42feaac"
      ],
      "layout": "IPY_MODEL_fb20d59bcf1941caa0b166101472cc32"
     }
    },
    "0f7033a6a02a4cc68a4abfaefbbbea5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0fe7edc171af41a383629e4004686408": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12153ec6ffbd40dfa1c86477314438ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f956020593944628b2a9f108fee4b3f",
      "max": 25,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4be3c071b2ea4674be58976d0eae098a",
      "value": 25
     }
    },
    "15ccc51d5ace4ef8b599645cb29dced5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99a08625fc164d2f9fb7ac62fdf8b105",
      "placeholder": "​",
      "style": "IPY_MODEL_a93d1c1e1c56473580e26e958f59e819",
      "value": "Downloading extra modules: 100%"
     }
    },
    "19bd1d7a24bc4da5a4038fac1b8fd6e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_433e112f7aa442f199d660213a59112a",
      "max": 1421700479,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aafe78aa3d5d4f79b616a5134b75ecc0",
      "value": 1421700479
     }
    },
    "1c6e102e6fa64872a9e530ab714a38ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d74e3ed9fa3469996d98d2ec5d16996": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1f956020593944628b2a9f108fee4b3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24b9a821c51d4cc4a347c632dfd71b77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_774f90868e154ef68755049961424e08",
      "placeholder": "​",
      "style": "IPY_MODEL_0963db3db27e45759d2ddd460ddb4b16",
      "value": "Map: 100%"
     }
    },
    "25be8e60468d4a868c96698953684a9d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "264a69ea350b467d8e18021d4f8936a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a8735e49d1e4e5782bf7c76be595976",
      "max": 5937,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d5fc8ac4b921451ca48d201f935bfba2",
      "value": 5937
     }
    },
    "273806b5fd5d47218bfc9049bc5b4304": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "294986c32c474f07b2da2ed5cd754cec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a3345bb71ef46eeb44e306f9e2efc78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a8735e49d1e4e5782bf7c76be595976": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2dbfcb7b95464171b3504ac43b05e661": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e9ac10b414143b9a4c5350194351508": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "30654f03b0d44278967543ad0a91683c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c904af7ae76d4508b44c5baa5291d87a",
      "placeholder": "​",
      "style": "IPY_MODEL_96bc16b7c669400a805df3e98e9de40f",
      "value": " 482/482 [00:00&lt;00:00, 11.3kB/s]"
     }
    },
    "31292df008e549cb9639ad475dc13c0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "354fbab478b24ae18d59822eadadc613": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_273806b5fd5d47218bfc9049bc5b4304",
      "placeholder": "​",
      "style": "IPY_MODEL_2a3345bb71ef46eeb44e306f9e2efc78",
      "value": " 5.94k/5.94k [00:00&lt;00:00, 262kB/s]"
     }
    },
    "3692b336ff20476787a29369d32f9288": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "369d588858ac4241a129786506ee0e5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ddd58d9d8fe4c19a4eaf75de6810726",
      "placeholder": "​",
      "style": "IPY_MODEL_1c6e102e6fa64872a9e530ab714a38ae",
      "value": "config.json: 100%"
     }
    },
    "3a18849ef083435daad014102b04b732": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3e4269bfcfa94d0fab397dfde02e5dce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41405b3f3fcd4738a057ab6fd194f01d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "427d0a6fb45d4632a566258df98981d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42a2000ee9fe4455ac3e652c0cc8c679": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "42ef79552fed419199269748f53c1ebe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e19a0ec223c349b39581a9c71651f189",
       "IPY_MODEL_12153ec6ffbd40dfa1c86477314438ec",
       "IPY_MODEL_6a0e0d61126c44f7ac845bc1c3669546"
      ],
      "layout": "IPY_MODEL_81628de9c3fe4e25a01002070cb9819d"
     }
    },
    "433e112f7aa442f199d660213a59112a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47d4b444c62e493880312c31275585f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4973a1c7b3664eab8bf3f479bd908b04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0b5f4eb26fd43058d4e98774546b6dd",
      "max": 482,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e83f63e4dfd3478abe6651e50006941f",
      "value": 482
     }
    },
    "4be3c071b2ea4674be58976d0eae098a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4c949815c9d245c6af3bf329cbb5e801": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_be3ec492445447e1b8cc95a0bd5bc02c",
       "IPY_MODEL_769ae4e48e504d87bfbdfa36ec1614fb",
       "IPY_MODEL_ce617425772a464c94dc24c84a446a59"
      ],
      "layout": "IPY_MODEL_3e4269bfcfa94d0fab397dfde02e5dce"
     }
    },
    "4f4d3d1bd8614042af4775654dd1c026": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "520d6e5ee91245b49e24a24ba94cc6eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "54d28b03b2d74b548836d9a1eb28bc7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6d86b99ab31417fb7fddbee678bde5d",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c6ea71dc470645c287abb35c6076696c",
      "value": 456318
     }
    },
    "5596f60851a046d2bc3ac9e5f42b8947": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5991d14fe66f4f589d226153b8410350": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05e632035050470185d1a615315cf52a",
      "placeholder": "​",
      "style": "IPY_MODEL_3a18849ef083435daad014102b04b732",
      "value": "Downloading builder script: 100%"
     }
    },
    "5a3dd23da65f48dda99e2e46ce447bcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ab6b00904a54b17b7bd9598f536dbae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d6e8f7950434391bb24ef82cace5972": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f49f6fecc9c4817a2ef94033b0777a8",
      "max": 203,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1d74e3ed9fa3469996d98d2ec5d16996",
      "value": 203
     }
    },
    "5f050946900b427288467332487e8790": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "641f4f5d2cde4ed0bf5bcdc990d4f722": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6555c35f2a324e99baa17fa22c52335f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_641f4f5d2cde4ed0bf5bcdc990d4f722",
      "placeholder": "​",
      "style": "IPY_MODEL_e90bb76d9dc744899d379c976dd3ed64",
      "value": " 1.42G/1.42G [00:14&lt;00:00, 204MB/s]"
     }
    },
    "655d4c402d814fd684d860e119f088c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3417018a6d44e3aa806b1ee8f25510f",
      "placeholder": "​",
      "style": "IPY_MODEL_edefab21c1464a0792789a4beb56f5b2",
      "value": "model.safetensors: 100%"
     }
    },
    "6686cdaf68f8452a9bd7668ddec17855": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25be8e60468d4a868c96698953684a9d",
      "placeholder": "​",
      "style": "IPY_MODEL_7550c83acaee4e969396c42739a35479",
      "value": " 3.34k/3.34k [00:00&lt;00:00, 119kB/s]"
     }
    },
    "66b4679853554256938f26fda42feaac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_294986c32c474f07b2da2ed5cd754cec",
      "placeholder": "​",
      "style": "IPY_MODEL_f7f29ae1463244d1a9793bb82bfaa7ca",
      "value": " 456k/456k [00:00&lt;00:00, 526kB/s]"
     }
    },
    "66cb9ebd67df4ff688a4b0de5eedf1fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bbe2d45f4daf486d8563b2e7e2b7263e",
       "IPY_MODEL_e48939ffb41e49de8ebc08a88bc86215",
       "IPY_MODEL_8ef1b9ab74c648c48d887586d8e00c94"
      ],
      "layout": "IPY_MODEL_9209d6a1132e422f97d13607db5415ba"
     }
    },
    "680850960d1c423582929cc27e89d3f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6a0e0d61126c44f7ac845bc1c3669546": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_31292df008e549cb9639ad475dc13c0d",
      "placeholder": "​",
      "style": "IPY_MODEL_680850960d1c423582929cc27e89d3f0",
      "value": " 25.0/25.0 [00:00&lt;00:00, 597B/s]"
     }
    },
    "6ce2e18f38d8439aa94747b5d5cefd1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_15ccc51d5ace4ef8b599645cb29dced5",
       "IPY_MODEL_7aeabe9a3f854acc85af35c4bcbf0c0b",
       "IPY_MODEL_6686cdaf68f8452a9bd7668ddec17855"
      ],
      "layout": "IPY_MODEL_8def38cad5f6457a9aa3236e4f0f109f"
     }
    },
    "6e3d89624b344ed0bfeb4d467aac27ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e6bac4a85614648abcfa756f3282a79": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70f14e6c997e450199dbfbe42272d0cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72dd4b9f82ac4d26822d7d84bd0b05bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7550c83acaee4e969396c42739a35479": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "75887d9b5592465a8a943636da571a9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75c3c75255aa42d59f0ba86707211791": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_655d4c402d814fd684d860e119f088c0",
       "IPY_MODEL_19bd1d7a24bc4da5a4038fac1b8fd6e5",
       "IPY_MODEL_6555c35f2a324e99baa17fa22c52335f"
      ],
      "layout": "IPY_MODEL_4f4d3d1bd8614042af4775654dd1c026"
     }
    },
    "769ae4e48e504d87bfbdfa36ec1614fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09a42adb77e44429a06b0d22093e45b9",
      "max": 1355863,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_72dd4b9f82ac4d26822d7d84bd0b05bc",
      "value": 1355863
     }
    },
    "774f90868e154ef68755049961424e08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77911929df414a598f59858d52506f49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_917ab47a5d4b43db9d0360445d4b3c4b",
      "placeholder": "​",
      "style": "IPY_MODEL_7d0a4bc14a114cccbb2c401bebf571ed",
      "value": "Downloading extra modules: "
     }
    },
    "7aeabe9a3f854acc85af35c4bcbf0c0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88f2e044a8034526b1a72a16df8d57d2",
      "max": 3344,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_42a2000ee9fe4455ac3e652c0cc8c679",
      "value": 3344
     }
    },
    "7d0a4bc14a114cccbb2c401bebf571ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f0e614edf03416ca98aaf0e3e2fcb2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f7033a6a02a4cc68a4abfaefbbbea5e",
      "placeholder": "​",
      "style": "IPY_MODEL_6e3d89624b344ed0bfeb4d467aac27ab",
      "value": " 4.07k/? [00:00&lt;00:00, 188kB/s]"
     }
    },
    "80a63717cb4f46758dc2058f2f579a8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7f747995bec4407bffe4439b306065f",
      "max": 1554,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5596f60851a046d2bc3ac9e5f42b8947",
      "value": 1554
     }
    },
    "81628de9c3fe4e25a01002070cb9819d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8653d8faf15b4794810e6efb19e7e415": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88f2e044a8034526b1a72a16df8d57d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8aec2a2cb7ae4eaa8cfb54607873cc8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b98fce06ad74cdfa796d07d3758625f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8def38cad5f6457a9aa3236e4f0f109f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ef1b9ab74c648c48d887586d8e00c94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e6bac4a85614648abcfa756f3282a79",
      "placeholder": "​",
      "style": "IPY_MODEL_520d6e5ee91245b49e24a24ba94cc6eb",
      "value": " 899k/899k [00:00&lt;00:00, 3.83MB/s]"
     }
    },
    "8f49f6fecc9c4817a2ef94033b0777a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "917ab47a5d4b43db9d0360445d4b3c4b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9209d6a1132e422f97d13607db5415ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96bc16b7c669400a805df3e98e9de40f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "991d717bea3d473b9f8eab8eb6f1ad00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75887d9b5592465a8a943636da571a9e",
      "max": 6270,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9e181d548ee5488f9a0c0bd58fbff6fe",
      "value": 6270
     }
    },
    "99a08625fc164d2f9fb7ac62fdf8b105": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ddd58d9d8fe4c19a4eaf75de6810726": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e181d548ee5488f9a0c0bd58fbff6fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a5cd3cc83ab444f19f0cbfa301114f9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea778689e02c4a769cfc4ad96ef8d511",
      "placeholder": "​",
      "style": "IPY_MODEL_c336459facae49b0a6ef1fdb22ac316f",
      "value": " 203/203 [00:00&lt;00:00, 1273.41 examples/s]"
     }
    },
    "a6d86b99ab31417fb7fddbee678bde5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a93d1c1e1c56473580e26e958f59e819": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aafe78aa3d5d4f79b616a5134b75ecc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ab79477865a2472c9ea5eb46fa864f5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "afe0f4e6930643fc9818b210e7d67bf8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0b5f4eb26fd43058d4e98774546b6dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3dbefd9921b440b9f25333878a5f1b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bbe2d45f4daf486d8563b2e7e2b7263e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41405b3f3fcd4738a057ab6fd194f01d",
      "placeholder": "​",
      "style": "IPY_MODEL_ab79477865a2472c9ea5eb46fa864f5e",
      "value": "vocab.json: 100%"
     }
    },
    "be3ec492445447e1b8cc95a0bd5bc02c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70f14e6c997e450199dbfbe42272d0cb",
      "placeholder": "​",
      "style": "IPY_MODEL_8653d8faf15b4794810e6efb19e7e415",
      "value": "tokenizer.json: 100%"
     }
    },
    "c336459facae49b0a6ef1fdb22ac316f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c6ea71dc470645c287abb35c6076696c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c70ca1f2df4a4441ab8c90c9475fb615": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e183e11461d44559aecefaa962ade471",
       "IPY_MODEL_264a69ea350b467d8e18021d4f8936a7",
       "IPY_MODEL_354fbab478b24ae18d59822eadadc613"
      ],
      "layout": "IPY_MODEL_8b98fce06ad74cdfa796d07d3758625f"
     }
    },
    "c7f747995bec4407bffe4439b306065f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c81a0a51f9a64bbc9b711606f915dde6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_24b9a821c51d4cc4a347c632dfd71b77",
       "IPY_MODEL_5d6e8f7950434391bb24ef82cace5972",
       "IPY_MODEL_a5cd3cc83ab444f19f0cbfa301114f9e"
      ],
      "layout": "IPY_MODEL_3692b336ff20476787a29369d32f9288"
     }
    },
    "c904af7ae76d4508b44c5baa5291d87a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce617425772a464c94dc24c84a446a59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfa192c1398b499cb6b6da15c4600495",
      "placeholder": "​",
      "style": "IPY_MODEL_8aec2a2cb7ae4eaa8cfb54607873cc8a",
      "value": " 1.36M/1.36M [00:00&lt;00:00, 2.49MB/s]"
     }
    },
    "d3417018a6d44e3aa806b1ee8f25510f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5fc8ac4b921451ca48d201f935bfba2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dcafc78aa9e8421b9dfc9400f544afbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfa192c1398b499cb6b6da15c4600495": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e183e11461d44559aecefaa962ade471": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2dbfcb7b95464171b3504ac43b05e661",
      "placeholder": "​",
      "style": "IPY_MODEL_2e9ac10b414143b9a4c5350194351508",
      "value": "Downloading builder script: 100%"
     }
    },
    "e19a0ec223c349b39581a9c71651f189": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2423a5a792d4546b42144e413a18405",
      "placeholder": "​",
      "style": "IPY_MODEL_5a3dd23da65f48dda99e2e46ce447bcd",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "e225cbf0242b465fa5156c4e26dca1ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_369d588858ac4241a129786506ee0e5c",
       "IPY_MODEL_4973a1c7b3664eab8bf3f479bd908b04",
       "IPY_MODEL_30654f03b0d44278967543ad0a91683c"
      ],
      "layout": "IPY_MODEL_dcafc78aa9e8421b9dfc9400f544afbf"
     }
    },
    "e48939ffb41e49de8ebc08a88bc86215": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_afe0f4e6930643fc9818b210e7d67bf8",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5f050946900b427288467332487e8790",
      "value": 898823
     }
    },
    "e714fecc0b924b90ae55f85f6e900535": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f77112dc70ad44e18095a01ecbd67257",
      "placeholder": "​",
      "style": "IPY_MODEL_b3dbefd9921b440b9f25333878a5f1b3",
      "value": " 6.27k/6.27k [00:00&lt;00:00, 233kB/s]"
     }
    },
    "e83f63e4dfd3478abe6651e50006941f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e90bb76d9dc744899d379c976dd3ed64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea778689e02c4a769cfc4ad96ef8d511": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edefab21c1464a0792789a4beb56f5b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f2423a5a792d4546b42144e413a18405": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f77112dc70ad44e18095a01ecbd67257": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7f29ae1463244d1a9793bb82bfaa7ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb20d59bcf1941caa0b166101472cc32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fed6ba63eece4cc48dd2aa14519342da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5991d14fe66f4f589d226153b8410350",
       "IPY_MODEL_991d717bea3d473b9f8eab8eb6f1ad00",
       "IPY_MODEL_e714fecc0b924b90ae55f85f6e900535"
      ],
      "layout": "IPY_MODEL_427d0a6fb45d4632a566258df98981d4"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
